{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8XHHT99-Slm"
   },
   "source": [
    "### Chapter 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **GAN ëª¨ë¸ ì´ë¯¸ì§€ ìƒì„±**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaV6bKLx-Sls"
   },
   "source": [
    "> ## í•™ìŠµ ëª©í‘œ\n",
    "\n",
    "- GAN(Generative Adversarial Network)ì˜ ê¸°ë³¸ ê°œë…ê³¼ êµ¬ì¡°ë¥¼ ì´í•´í•˜ê³  ì‹¤ë¬´ì— ì ìš©í•  ìˆ˜ ìˆë‹¤. \n",
    "- ìƒì„±ì(Generator)ì™€ íŒë³„ì(Discriminator)ì˜ ì—­í•  ë° ìƒí˜¸ì‘ìš©ì„ ì´í•´í•˜ê³ , PyTorchë¥¼ ì‚¬ìš©í•˜ì—¬ GAN ëª¨ë¸ì„ êµ¬ì¶•, í›ˆë ¨ì‹œí‚¬ ìˆ˜ ìˆë‹¤.\n",
    "- GANì˜ ë‹¤ì–‘í•œ ë³€í˜• ë° ì‘ìš© ì‚¬ë¡€ë¥¼ íƒìƒ‰í•˜ê³  ì‹¤ìŠµí•˜ë©°, ìƒì„±ëœ ìƒ˜í”Œì˜ í’ˆì§ˆì„ í‰ê°€í•˜ê³ , ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì „ëµì„ ì œì‹œí•  ìˆ˜ ìˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GAN(Generative Adversarial Network)`\n",
    "\n",
    "**â–  GANì˜ ì •ì˜** : GANì€ ìƒì„±ì  ì ëŒ€ ì‹ ê²½ë§(Generative Adversarial Network)ìœ¼ë¡œ, ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. \n",
    "- Goodfellow, lan et al. (2014) ë…¼ë¬¸ì— ê²Œì¬ëœ ë‚´ìš©ì…ë‹ˆë‹¤.\n",
    "- **Generative Adversarial NetworksëŠ” í¸ì˜ìƒ GAN, ê², ë˜ëŠ” ê°„**ìœ¼ë¡œë„ ë¶€ë¥¸ë‹¤. \n",
    "- CNNì˜ ì°½ì‹œìì´ì, í˜„ì¬ facebook AI ì´ê´„ì„ ë‹´ë‹¹í•˜ëŠ” ì–€ ë£¨í°ì€ GANì€ ìµœê·¼ 10ë…„ê°„ ë¨¸ì‹ ëŸ¬ë‹ ë¶„ì•¼ì—ì„œ ê°€ì¥ ë©‹ì§„ ì•„ì´ë””ì–´ê°€ Adversarial NetworkëŠ” ì ëŒ€ì ì¸ ì‹ ê²½ë§ì´ ì„œë¡œ ê²½ìŸí•˜ë©´ì„œ ê°€ì§œ ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ëŠ” ê²ƒì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
    "\n",
    "**â–  ëª©ì ** : GANì€ í˜„ì‹¤ê° ìˆëŠ” ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ìƒì„±ìì™€, ì‹¤ì œ ë°ì´í„°ì™€ ìƒì„±ëœ ë°ì´í„°ë¥¼ êµ¬ë³„í•˜ë ¤ëŠ” íŒë³„ìì˜ ë‘ ë„¤íŠ¸ì›Œí¬ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.1 GAN ëª¨ë¸ êµ¬ì¡°"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GAN(Generative Adversarial Network)ì€ ë‘ ê°œì˜ ì‹ ê²½ë§ ëª¨ë¸, ì¦‰ ìƒì„±ì(Generator)ì™€ íŒë³„ì(Discriminator)ê°€ ê²½ìŸí•˜ëŠ” êµ¬ì¡°ë¡œ ì´ë£¨ì–´ì ¸ ìˆìŠµë‹ˆë‹¤. \n",
    "\n",
    "ìƒì„±ìëŠ” ë°ì´í„°ë¥¼ ìƒì„±í•˜ê³ , íŒë³„ìëŠ” ìƒì„±ëœ ë°ì´í„°ê°€ ì‹¤ì œ ë°ì´í„°ì¸ì§€ ì•„ë‹Œì§€ë¥¼ êµ¬ë³„í•˜ë ¤ê³  í•©ë‹ˆë‹¤. \n",
    "\n",
    "ì´ ë‘ ë„¤íŠ¸ì›Œí¬ëŠ” ì„œë¡œ ê²½ìŸí•˜ë©´ì„œ ì„±ëŠ¥ì„ ê°œì„ í•´ ë‚˜ê°€ê³ , ê²°êµ­ ìƒì„±ìëŠ” ë§¤ìš° ì‚¬ì‹¤ì ì¸ ë°ì´í„°ë¥¼ ë§Œë“¤ì–´ë‚´ê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) ê¸°ë³¸ì›ë¦¬\n",
    "-   **ìƒì„±ì (Generator, G)**\n",
    "    \n",
    "    -   **ì—­í• ** : ìƒì„±ìëŠ” ë¬´ì‘ìœ„ ë…¸ì´ì¦ˆ(ì ì¬ ê³µê°„ ë²¡í„°)ë¥¼ ì…ë ¥ë°›ì•„ ì‹¤ì œ ë°ì´í„°ì™€ ìœ ì‚¬í•œ ê°€ì§œ ë°ì´í„°ë¥¼ ìƒì„±í•˜ëŠ” ì—­í• ì„ ë§¡ìŠµë‹ˆë‹¤.\n",
    "    -   **êµ¬ì¡°** : ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìˆ˜ì˜ ë ˆì´ì–´ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë©°, ì™„ì „ ì—°ê²°ì¸µê³¼ í•©ì„±ê³±ì¸µì„ í¬í•¨í•©ë‹ˆë‹¤. ì¶œë ¥ì¸µì€ ìƒì„±í•˜ë ¤ëŠ” ë°ì´í„°ì˜ ì°¨ì›ì— ë§ì¶° ì„¤ê³„ë©ë‹ˆë‹¤.\n",
    "    -   **ì…ë ¥** : ëœë¤ ë…¸ì´ì¦ˆ(ì¼ë°˜ì ìœ¼ë¡œ ì ì¬ ë²¡í„° z)ë¥¼ ë°›ì•„, ì´ë¥¼ ë³€í™˜í•˜ì—¬ ìƒˆë¡œìš´ ìƒ˜í”Œì„ ë§Œë“¤ì–´ëƒ…ë‹ˆë‹¤.\n",
    "    -   **ëª©í‘œ** : ìƒì„±ìëŠ” íŒë³„ìê°€ ì§„ì§œ ë°ì´í„°ì¸ì§€ ê°€ì§œ ë°ì´í„°ì¸ì§€ êµ¬ë³„í•  ìˆ˜ ì—†ê²Œë”, íŒë³„ìë¥¼ ì†ì¼ ìˆ˜ ìˆëŠ” ì§ˆ ë†’ì€ ê°€ì§œ ë°ì´í„°ë¥¼ ìƒì‚°í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•©ë‹ˆë‹¤.\n",
    "    \n",
    "-   **íŒë³„ì (Discriminator, D)**\n",
    "    \n",
    "    -   **ì—­í• ** : íŒë³„ìëŠ” ì…ë ¥ëœ ë°ì´í„°ê°€ ì§„ì§œ ë°ì´í„°ì¸ì§€ ìƒì„±ìê°€ ë§Œë“  ê°€ì§œ ë°ì´í„°ì¸ì§€ êµ¬ë³„í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.\n",
    "    -   **êµ¬ì¡°** : ì—¬ëŸ¬ ê°œì˜ ë ˆì´ì–´ë¡œ ì´ë£¨ì–´ì ¸ ìˆìœ¼ë©°, ë§ˆì§€ë§‰ ì¶œë ¥ì¸µì€ ì…ë ¥ëœ ë°ì´í„°ê°€ ì§„ì§œì¼ í™•ë¥ ì„ ì´ì§„ í˜•íƒœë¡œ ì œê³µí•©ë‹ˆë‹¤.\n",
    "    -   **ì…ë ¥** : ì‹¤ì œ ë°ì´í„°ì™€ ìƒì„±ìê°€ ìƒì‚°í•œ ê°€ì§œ ë°ì´í„°ë¥¼ ëª¨ë‘ ë°›ì•„ë“¤ì´ë©°, ì´ë¥¼ íŒë³„í•˜ì—¬ ì •í™•í•œ ê²°ê³¼ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.\n",
    "    -   **ëª©í‘œ** : íŒë³„ìëŠ” ì£¼ì–´ì§„ ë°ì´í„°ê°€ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ ì •í™•íˆ ë¶„ë¥˜í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ë©°, ì´ë¥¼ í†µí•´ ìƒì„±ìì˜ ì„±ê³¼ë¥¼ í‰ê°€í•˜ëŠ” ê¸°ì¤€ ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "    \n",
    "-   **í›ˆë ¨ ê³¼ì •**\n",
    "    \n",
    "    -   **ì ëŒ€ì  í›ˆë ¨ (Adversarial Training)** : ìƒì„±ìì™€ íŒë³„ìëŠ” ì„œë¡œ ì ëŒ€ì ì¸ ê´€ê³„ë¥¼ ìœ ì§€í•˜ë©° í•™ìŠµí•©ë‹ˆë‹¤. ìƒì„±ìëŠ” íŒë³„ìë¥¼ ì†ì´ë ¤ í•˜ê³ , íŒë³„ìëŠ” ìƒì„±ìê°€ ë§Œë“  ê°€ì§œ ë°ì´í„°ë¥¼ ë” ì˜ êµ¬ë³„í•˜ë ¤ ë…¸ë ¥í•©ë‹ˆë‹¤.\n",
    "    -   **ê²½ìŸì  í•™ìŠµ** : ë‘ ë„¤íŠ¸ì›Œí¬ëŠ” ì§€ì†ì ì¸ ê²½ìŸì„ í†µí•´ ë°œì „í•˜ê²Œ ë˜ë©°, ê²°ê³¼ì ìœ¼ë¡œ ìƒì„±ìëŠ” ì ì  ë” í˜„ì‹¤ê° ìˆëŠ” ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤. ì´ ê³¼ì •ì—ì„œ ê° ë„¤íŠ¸ì›Œí¬ëŠ” ì„œë¡œì˜ ì„±ëŠ¥ì„ ê°œì„ í•˜ê¸° ìœ„í•œ í”¼ë“œë°±ì„ ì£¼ê³ ë°›ìœ¼ë©°, ê°ìì˜ ëŠ¥ë ¥ì„ ê·¹ëŒ€í™”í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) GAN ì‘ë™ ì›ë¦¬\n",
    "\n",
    "-   **í›ˆë ¨ ë‹¨ê³„**:\n",
    "    \n",
    "    1.  íŒë³„ìëŠ” ì‹¤ì œ ë°ì´í„°ì™€ ìƒì„±ìê°€ ë§Œë“  ë°ì´í„°ë¥¼ ì…ë ¥ë°›ì•„ ë‘ ë°ì´í„°ë¥¼ êµ¬ë³„í•©ë‹ˆë‹¤.\n",
    "    2.  ìƒì„±ìëŠ” íŒë³„ìì˜ í”¼ë“œë°±ì„ ë°”íƒ•ìœ¼ë¡œ ìì‹ ì˜ ì¶œë ¥ì„ ê°œì„ í•©ë‹ˆë‹¤.\n",
    "    3.  ì´ ê³¼ì •ì„ ë°˜ë³µí•˜ì—¬ ë‘ ëª¨ë¸ì´ ì„œë¡œ ë°œì „í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) GANì˜ ì†ì‹¤ í•¨ìˆ˜\n",
    "\n",
    "-   **ì†ì‹¤ í•¨ìˆ˜**:\n",
    "    \n",
    "    -   ìƒì„±ìì˜ ëª©í‘œëŠ” íŒë³„ìë¥¼ ì†ì´ëŠ” ê²ƒì´ê³ , íŒë³„ìì˜ ëª©í‘œëŠ” ìƒì„±ìê°€ ë§Œë“  ê°€ì§œ ë°ì´í„°ë¥¼ ì˜ êµ¬ë³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. \n",
    "    \n",
    "        ê°ê°ì˜ ì†ì‹¤ í•¨ìˆ˜ëŠ” ì´ ëª©í‘œì— ë§ì¶° ì •ì˜ë©ë‹ˆë‹¤.\n",
    "\n",
    "\n",
    "- **GANì˜ ì†ì‹¤ í•¨ìˆ˜ëŠ” ë‘ ê°€ì§€**ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:\n",
    "\n",
    "  - **ìƒì„±ì ì†ì‹¤** : ìƒì„±ìê°€ íŒë³„ìë¥¼ ì†ì¼ ìˆ˜ ìˆë„ë¡ í•™ìŠµí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "\n",
    "    ìƒì„±ìê°€ ë§Œë“  ë°ì´í„° ğº(ğ‘§)ì— ëŒ€í•´ íŒë³„ìê°€ 1ì„ ì˜ˆì¸¡í•˜ë„ë¡ ìœ ë„.\n",
    "\n",
    "  - **íŒë³„ì ì†ì‹¤** : íŒë³„ìê°€ ì‹¤ì œ ë°ì´í„°ì™€ ê°€ì§œ ë°ì´í„°ë¥¼ ì˜ êµ¬ë³„í•˜ë„ë¡ í•™ìŠµí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "\n",
    "    ì‹¤ì œ ë°ì´í„° ğ‘¥ì— ëŒ€í•´ íŒë³„ìê°€ 1ì„ ì˜ˆì¸¡í•˜ë„ë¡ ìœ ë„.\n",
    "\n",
    "    ìƒì„±ëœ ê°€ì§œ ë°ì´í„° ğº(ğ‘§)ì— ëŒ€í•´ íŒë³„ìê°€ 0ì„ ì˜ˆì¸¡í•˜ë„ë¡ ìœ ë„."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GANì„ ì²˜ìŒ ì œì•ˆí•œ Ian GoodfellowëŠ” <ê²½ì°°ê³¼ ìœ„ì¡°ì§€íë²”>ìœ¼ë¡œ ë¹„ìœ `í•˜ì˜€ë‹¤. \n",
    "\n",
    "-  ì§€íìœ„ì¡°ë²”ì´ ì²˜ìŒì—ëŠ” ëˆì„ ì œëŒ€ë¡œ ëª» ë§Œë“¤ì–´ ê²½ì°°ì´ ìœ„ì¡°ì§€íë¥¼ ì œëŒ€ë¡œ êµ¬ë¶„í•˜ì—¬ ê²€ê±°ì— ì„±ê³µí–ˆë‹¤. \n",
    "\n",
    "   ì´í›„, ì§€íìœ„ì¡°ë²”ì€ ë”ìš± ë°œì „ëœ ê¸°ìˆ ë¡œ ì§€íë¥¼ ìœ„ì¡°í•œë‹¤. \n",
    "\n",
    "-  ìœ„ì¡°ì§€íë²”ì€ ì§„ì§œ ê°™ì€ ìœ„ì¡°ì§€íë¥¼ ë§Œë“¤ì–´(ìƒì„±, gnerater) ê²½ì°°ì„ ì†ì´ê³ , ê²½ì°°ì€ ì§„ì§œì™€ ê°€ì§œ í™”íë¥¼ êµ¬ë¶„(ë¶„ë¥˜, discriminator)í•˜ê¸° ë…¸ë ¥í•œë‹¤.\n",
    "\n",
    "   ê²°êµ­ ìœ„ì¡°ì§€íë²”ì€ êµ¬ë¶„í•˜ê¸° ì–´ë ¤ìš´ ìœ„ì¡°ì§€íë¥¼ ë§Œë“¤ê²Œ ëœë‹¤. ê²½ì°°ì€ ì´ê²Œ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ êµ¬ë³„í•˜ê¸° ê°€ì¥ ì–´ë ¤ìš´ 50% í™•ë¥ ì— ìˆ˜ë ´í•˜ê²Œ ëœë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `The GAN Objective Function`\n",
    "\n",
    "<table style=\"border-collapse: collapse; width: 100%;\" border=\"1\" data-ke-align=\"alignLeft\"><tbody><tr><td style=\"width: 30%;\">D should maximize V(D, G)&nbsp;<br>: D ì…ì¥ì—ì„œ Vê°€ ìµœëŒ“ê°’</td><td style=\"width: 70%; text-align: left;\">1. Dê°€ êµ¬ë¶„ì„ ì˜í•˜ëŠ” ê²½ìš°, ë§Œì•½ Real dataê°€ ë“¤ì–´ì˜¤ë©´<br><b>D(x) = 1,&nbsp;D(G(z)) = 0<br></b>: ì§„ì§œë©´ 1, ê°€ì§œë©´ 0ì„ ë‚´ë±‰ìŒ. (G(z)ì— ê°€ì§œê°€ ë“¤ì–´ì˜¨ ê²½ìš°, ê°€ì§œë¥¼ ì˜ êµ¬ë¶„í•œ ê²ƒì„)&nbsp;&nbsp;<br>- Dì˜ ì…ì¥ì—ì„œëŠ” minmaxV(D, G) = 0&nbsp; - Maximizeë¥¼ ìœ„í•´ 0ìœ¼ë¡œ ë³´ë‚´ëŠ” ê²Œ Dì˜ ì…ì¥ì—ì„œëŠ” ê°€ì¥ ì¢‹ìŒ&nbsp;<br>&nbsp;</td></tr><tr><td style=\"width: 30%;\">D should minimize V(D, G)<br>: G ì…ì¥ì—ì„œ Vê°€ ìµœì†Ÿê°’</td><td style=\"width: 70%; text-align: left;\">2. Dê°€ êµ¬ë¶„ì„ ëª»í•˜ëŠ” ê²½ìš°, ë§Œì•½ Real dataê°€ ë“¤ì–´ì˜¤ë©´<br><b>D(G(z)) = 1<br></b>: ì§„ì§œë¥¼ 0, ê°€ì§œë¥¼ 1ë¡œ ë‚´ë±‰ìŒ (ì§„ì§œë¥¼ êµ¬ë¶„í•˜ì§€ ëª»í•˜ê³  ê°€ì§œë¥¼ ì§„ì§œë¡œ ì°©ê°í•¨)&nbsp;<br>- log ì•ˆì˜ D ê°’ì´ 0ì´ ë˜ì–´, V ê°’ì´&nbsp;-âˆë¡œ ë¨&nbsp;<br>- Minimizeë¥¼ ìœ„í•´&nbsp;-âˆë¡œ ë³´ë‚´ëŠ” ê²Œ G ì…ì¥ì—ì„œëŠ” ê°€ì¥ ì¢‹ìŒ</td></tr><tr><td style=\"width: 100%; text-align: left;\" colspan=\"2\">- x : real ì´ë¯¸ì§€<br>- z : latent code&nbsp;<br>- G(z) : fake ì´ë¯¸ì§€<br>- D(x) : real ì´ë¯¸ì§€ë¼ê³  ë¶„ë¥˜í•œ í™•ë¥ <br>- D(G(z)) : Dê°€ fakeë¼ê³  ë¶„ë¥˜í•œ í™•ë¥ <br><br>-&gt;<b>&nbsp;G(z)ëŠ” D(G(z))ê°€ 1ë¡œ íŒë‹¨í•˜ë„ë¡ í•™ìŠµí•˜ê³ , D(G(z))ëŠ” 0ìœ¼ë¡œ íŒë‹¨í•˜ë„ë¡ í•™ìŠµí•¨</b></td></tr></tbody></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/gan.png\" width=\"800\" height=\"\" >\n",
    "<figcaption>ê·¸ë¦¼. GANë…¼ë¬¸ ë¦¬ë·° ì´ë¯¸ì§€</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ê´€ì ì—ì„œ ë‹¤ì‹œ í•´ì„í•˜ë©´, Generaterì—ì„œ inputì—ì„œ ì“°ë ˆê¸°(garbage) ê°’ì„ ë³´ë‚´ë„ \n",
    "\n",
    "output(ìœ„ì¡°ì§€í, ì‹¤ì œëŠ” ì´ë¯¸ì§€)ì€ ì‹¤ì œì™€ ê°€ì§œë¥¼ êµ¬ë¶„í•  ìˆ˜ ì—†ê²Œë”(adversarial) ë§Œë“¤ê²Œ ëœë‹¤.\n",
    "\n",
    "- GeneratorëŠ” ê¸°ì¡´ ìƒ˜í”Œ(training, real) ë¶„í¬ë¥¼ íŒŒì•…í•˜ì—¬ ìƒˆë¡œìš´ ìƒ˜í”Œ(fake)ì„ ìƒì„±í•¨\n",
    "- DiscriminatorëŠ” ìƒ˜í”Œì´ Generator ë˜ëŠ” Training ì¤‘ ì–´ë””ì—ì„œ ì˜¨ê±´ì§€ í™•ë¥ ì„ í‰ê°€í•¨ (Minimax tow-player game)\n",
    "- Genertaorê°€ Discriminator ë¶„í¬ë¥¼ ì™„ë²½í•œ ìˆ˜ì¤€ìœ¼ë¡œ ë³µì›í•˜ë©´ Discriminatorê°€ Generatorì˜ ì‚°ì¶œë¬¼(fake)ì™€ Training(real)ì„ êµ¬ë¶„í•  í™•ë¥ ì€ 1/2ê°€ ë¨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Q\\_model(x|z) : ì •ì˜í•˜ê³ ì í•˜ëŠ” zê°’ì„ ì¤¬ì„ ë•Œ x ì´ë¯¸ì§€ë¥¼ ë‚´ë³´ë‚´ëŠ” ëª¨ë¸\n",
    "-   P\\_data(x) : xë¼ëŠ” data distributionì€ ìˆì§€ë§Œ ì–´ë–»ê²Œ ìƒê¸´ì§€ëŠ” ëª¨ë¥´ë¯€ë¡œ, P ëª¨ë¸ì„ Q ëª¨ë¸ì— ê°€ê¹ê²Œ ê°€ë„ë¡ í•¨\n",
    "-   **íŒŒë€ ì ì„  ---**Â Â : discriminator distribution (ë¶„ë¥˜ ë¶„í¬) > í•™ìŠµì„ ë°˜ë³µí•˜ë‹¤ë³´ë©´ ê°€ì¥ êµ¬ë¶„í•˜ê¸° ì–´ë ¤ìš´ êµ¬ë³„ í™•ë¥ ì¸ 1/2 ìƒíƒœê°€ ë¨\n",
    "-   **ë…¹ìƒ‰ ì„  â»**Â : generative distribution (ê°€ì§œ ë°ì´í„° ë¶„í¬)\n",
    "-   **ê²€ì€ìƒ‰ ì ì„  ---**Â : data generating distribution (ì‹¤ì œ ë°ì´í„° ë¶„í¬)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/gan2.png\" width=\"800\" height=\"\" >\n",
    "<figcaption>ê·¸ë¦¼. GAN í•™ìŠµ ê³¼ì • (ì¶œì²˜ : Generative Adversarial Nets Goodfellow, Ian et al. 2014)</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) GANì˜ ë³€í˜•\n",
    "\n",
    "-   **Conditional GAN (cGAN)** :\n",
    "    -   íŠ¹ì • ì¡°ê±´ì— ë§ì¶° ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” GANì…ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, íŠ¹ì • í´ë˜ìŠ¤ì— ì†í•˜ëŠ” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    \n",
    "-   **CycleGAN** :\n",
    "    -   ë‘ ë„ë©”ì¸ ê°„ì˜ ì´ë¯¸ì§€ ë³€í™˜ì„ ìœ„í•œ GANìœ¼ë¡œ, ì˜ˆë¥¼ ë“¤ì–´ ì‚¬ì§„ì„ ê·¸ë¦¼ ìŠ¤íƒ€ì¼ë¡œ ë°”ê¾¸ëŠ” ë° ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    \n",
    "-   **StyleGAN** :\n",
    "    -   ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ ëª¨ë¸ë¡œ, ìŠ¤íƒ€ì¼ ì „ì´ ê¸°ëŠ¥ì„ ì¶”ê°€í•˜ì—¬ ë‹¤ì–‘í•œ ìŠ¤íƒ€ì¼ë¡œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    \n",
    "\n",
    "### 5) GANì˜ ì‘ìš© ì‚¬ë¡€ \n",
    "\n",
    "-   **ì´ë¯¸ì§€ ìƒì„±** : ê³ í•´ìƒë„ ì´ë¯¸ì§€ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìƒì„±í•´ë‚´ëŠ” ë° í™œìš©ë©ë‹ˆë‹¤.\n",
    "-   **ë°ì´í„° ì¦ê°•** : ë¶€ì¡±í•œ ë°ì´í„°ì…‹ì„ ë³´ì™„í•˜ê¸° ìœ„í•´ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "-   **ì˜ˆìˆ  ë° ë””ìì¸** : ì˜ˆìˆ  ì‘í’ˆì„ ìƒì„±í•˜ê±°ë‚˜ ë””ìì¸ ì•„ì´ë””ì–´ë¥¼ ì‹œê°ì ìœ¼ë¡œ í‘œí˜„í•˜ëŠ” ë° ì‚¬ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13.2 GAN(Generative Adversarial Network) ëª¨ë¸ êµ¬í˜„"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://vis-www.cs.umass.edu/lfw/#deepfunnel-anchor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/13.4_lfw.png\" width=\"800\" height=\"\" >\n",
    "<figcaption>ê·¸ë¦¼ 13.4 lfw(Labeled Faces in the Wild) </figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- CUDA ì„¤ì¹˜ì™€ CUDA ë²„ì „ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/gpu.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"./image/gpu2.png\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LFW(Labeled Faces in the Wild) ë°ì´í„°ì…‹\n",
    "- LFW (Labeled Faces in the Wild) ë°ì´í„°ì…‹ì€ ì–¼êµ´ ì¸ì‹ ë° ë¶„ë¥˜ë¥¼ ìœ„í•œ ìœ ëª…í•œ ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.\n",
    "- LFW ë°ì´í„°ì…‹ì„ ì‚¬ìš©í•´ ì–¼êµ´ì„ ìƒì„±í•˜ëŠ” GANì„ í•™ìŠµí•˜ê³ , í•™ìŠµ ê³¼ì •ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ í™•ì¸"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜**\n",
    "\n",
    "**2. LFW ë°ì´í„°ì…‹ ë¡œë”©**\n",
    "- torchvision ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ LFW ë°ì´í„°ì…‹ì„ ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "**3. GAN ëª¨ë¸ ì„¤ê³„**\n",
    "- Generator (ìƒì„±ì): ë…¸ì´ì¦ˆ ë²¡í„°ë¥¼ ì…ë ¥ë°›ì•„ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.\n",
    "- Discriminator (íŒë³„ì): ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ë¥¼ íŒë³„í•©ë‹ˆë‹¤.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. ìƒì„±ì(Generator) ëª¨ë¸ ì •ì˜\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 256),   # ì ì¬ ë²¡í„° zì˜ ê¸¸ì´ë¥¼ 100ìœ¼ë¡œ ì„¤ì •\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 28 * 28),  # MNIST ì´ë¯¸ì§€ í¬ê¸°\n",
    "            nn.Tanh()  # ì¶œë ¥ ê°’ì„ -1~1ë¡œ ì •ê·œí™”\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).view(-1, 1, 28, 28)  # 28x28 ì´ë¯¸ì§€ë¡œ ë³€í™˜\n",
    "\n",
    "\n",
    "# 2. íŒë³„ì(Discriminator) ëª¨ë¸ ì •ì˜\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 1024),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),  # ì§„ì§œ/ê°€ì§œë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•œ ì¶œë ¥\n",
    "            nn.Sigmoid()  # í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "# 3. ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # ë°ì´í„° ì •ê·œí™”\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "\n",
    "# 4. GAN í›ˆë ¨ í•¨ìˆ˜ ì •ì˜\n",
    "def train_gan(generator, discriminator, train_loader, num_epochs=50):\n",
    "    criterion = nn.BCELoss()  # ì´ì§„ êµì°¨ ì—”íŠ¸ë¡œí”¼ ì†ì‹¤ í•¨ìˆ˜\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=0.0002)\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        for real_images, _ in train_loader:\n",
    "            batch_size = real_images.size(0)\n",
    "            real_labels = torch.ones(batch_size, 1)\n",
    "            fake_labels = torch.zeros(batch_size, 1)\n",
    "\n",
    "            # íŒë³„ì í•™ìŠµ\n",
    "            optimizer_d.zero_grad()\n",
    "            outputs = discriminator(real_images)\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            d_loss_real.backward()\n",
    "\n",
    "            noise = torch.randn(batch_size, 100)  # ëœë¤ ë…¸ì´ì¦ˆ ìƒì„±\n",
    "            fake_images = generator(noise)\n",
    "            outputs = discriminator(fake_images.detach())\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            d_loss_fake.backward()\n",
    "            optimizer_d.step()\n",
    "\n",
    "            # ìƒì„±ì í•™ìŠµ\n",
    "            optimizer_g.zero_grad()\n",
    "            outputs = discriminator(fake_images)\n",
    "            g_loss = criterion(outputs, real_labels)  # ìƒì„±ì ì†ì‹¤\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], d_loss: {d_loss_real.item() + d_loss_fake.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
    "\n",
    "\n",
    "# 5. ê²°ê³¼ í™•ì¸ì„ ìœ„í•œ ì´ë¯¸ì§€ ì¶œë ¥ í•¨ìˆ˜ ì •ì˜\n",
    "def show_generated_images(generator, num_images=16):\n",
    "    noise = torch.randn(num_images, 100)\n",
    "    generated_images = generator(noise)\n",
    "    generated_images = generated_images.detach().numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(4, 4, i + 1)\n",
    "        plt.imshow(generated_images[i][0], cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# 6. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ë° í›ˆë ¨ ì‹œì‘\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "train_gan(generator, discriminator, train_loader)  # train_loader ì¶”ê°€\n",
    "\n",
    "# 7. ìƒì„±ëœ ì´ë¯¸ì§€ í™•ì¸\n",
    "show_generated_images(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch torchvision matplotlib scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "z_dim = 100\n",
    "lr = 0.0002\n",
    "epochs = 200\n",
    "sample_interval = 500\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¡œë”© ë° ì „ì²˜ë¦¬\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "lfw_dataset = datasets.LFWPeople(root='./data', split='train', transform=transform, download=True)\n",
    "dataloader = DataLoader(lfw_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Generator ëª¨ë¸\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(z_dim, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 3*64*64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        return x.view(-1, 3, 64, 64)\n",
    "\n",
    "# Discriminator ëª¨ë¸\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3*64*64, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3*64*64)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator(z_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        batch_size = imgs.size(0)\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        # ì§„ì§œ ì´ë¯¸ì§€ ë ˆì´ë¸” 1, ê°€ì§œ ì´ë¯¸ì§€ ë ˆì´ë¸” 0\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # -------------------------\n",
    "        #  Discriminator í•™ìŠµ\n",
    "        # -------------------------\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # ì§„ì§œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì†ì‹¤ ê³„ì‚°\n",
    "        real_output = discriminator(real_imgs)\n",
    "        d_loss_real = criterion(real_output, real_labels)\n",
    "\n",
    "        # ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì†ì‹¤ ê³„ì‚°\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        fake_output = discriminator(fake_imgs.detach())\n",
    "        # detach()ë¡œ generatorê°€ í•™ìŠµë˜ì§€ ì•Šë„ë¡ í•¨\n",
    "        d_loss_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # ì´ discriminator ì†ì‹¤\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # -------------------------\n",
    "        #  Generator í•™ìŠµ\n",
    "        # -------------------------\n",
    "        optimizer_g.zero_grad()\n",
    "\n",
    "        # generatorì˜ ëª©í‘œëŠ” íŒë³„ìê°€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ì§„ì§œë¡œ ë¶„ë¥˜í•˜ê²Œ ë§Œë“œëŠ” ê²ƒ\n",
    "        fake_output = discriminator(fake_imgs)\n",
    "        g_loss = criterion(fake_output, real_labels)\n",
    "        # fake ì´ë¯¸ì§€ë¥¼ ì§„ì§œë¡œ íŒë³„í•˜ë„ë¡ í•¨\n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{epochs}], Step [{i}/{len(dataloader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}')\n",
    "\n",
    "        # ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥ (sample_intervalë§ˆë‹¤)\n",
    "        if (epoch * len(dataloader) + i) % sample_interval == 0:\n",
    "            save_image(fake_imgs.data[:25], f'./output/fake_images_epoch_{epoch+1}_step_{i}.png', nrow=5, normalize=True)\n",
    "\n",
    "# í•™ìŠµ í›„ ìµœì¢… ìƒì„±ëœ ì´ë¯¸ì§€ ì‹œê°í™”\n",
    "z = torch.randn(25, z_dim).to(device)\n",
    "fake_imgs = generator(z)\n",
    "\n",
    "# ìƒì„±ëœ ì´ë¯¸ì§€ ì‹œê°í™”\n",
    "grid_img = torchvision.utils.make_grid(fake_imgs, nrow=5, normalize=True)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(grid_img.permute(1, 2, 0).cpu().detach().numpy())\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.use_deterministic_algorithms(False)\n",
    "# Deterministic Algorithms ë¹„í™œì„±í™”: PyTorchì˜ ê²°ì •ë¡ ì  ì•Œê³ ë¦¬ì¦˜ ëª¨ë“œë¥¼ ë¹„í™œì„±í™” í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ ì½”ë“œë‚˜ ìŠ¤í¬ë¦½íŠ¸ì—ì„œ ì•„ë˜ì™€ ê°™ì€ ì½”ë“œë¥¼ ì¶”ê°€í•˜ì—¬ ë¹„í™œì„±í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 128\n",
    "z_dim = 100\n",
    "lr = 0.0002\n",
    "epochs = 200\n",
    "sample_interval = 500\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë¡œë”© ë° ì „ì²˜ë¦¬\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "lfw_dataset = datasets.LFWPeople(root='./data', split='train', transform=transform, download=True)\n",
    "dataloader = DataLoader(lfw_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Generator ëª¨ë¸\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Linear(1024, 3*64*64),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        x = self.fc(z)\n",
    "        return x.view(-1, 3, 64, 64)\n",
    "\n",
    "# Discriminator ëª¨ë¸\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(3*64*64, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 3*64*64)\n",
    "        return self.fc(x)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "generator = Generator(z_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
    "\n",
    "# ì´ë¯¸ì§€ ì €ì¥ í´ë” ìƒì„±\n",
    "os.makedirs('./output', exist_ok=True)\n",
    "\n",
    "# í•™ìŠµ ë£¨í”„\n",
    "for epoch in range(epochs):\n",
    "    for i, (imgs, _) in enumerate(dataloader):\n",
    "        batch_size = imgs.size(0)\n",
    "        real_imgs = imgs.to(device)\n",
    "\n",
    "        # ì§„ì§œ ì´ë¯¸ì§€ ë ˆì´ë¸” 1, ê°€ì§œ ì´ë¯¸ì§€ ë ˆì´ë¸” 0\n",
    "        real_labels = torch.ones(batch_size, 1).to(device)\n",
    "        fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "        # -------------------------\n",
    "        #  Discriminator í•™ìŠµ\n",
    "        # -------------------------\n",
    "        optimizer_d.zero_grad()\n",
    "\n",
    "        # ì§„ì§œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì†ì‹¤ ê³„ì‚°\n",
    "        real_output = discriminator(real_imgs)\n",
    "        d_loss_real = criterion(real_output, real_labels)\n",
    "\n",
    "        # ê°€ì§œ ì´ë¯¸ì§€ì— ëŒ€í•´ ì†ì‹¤ ê³„ì‚°\n",
    "        z = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake_imgs = generator(z)\n",
    "        fake_output = discriminator(fake_imgs.detach())\n",
    "        # detach()ë¡œ generatorê°€ í•™ìŠµë˜ì§€ ì•Šë„ë¡ í•¨\n",
    "        d_loss_fake = criterion(fake_output, fake_labels)\n",
    "\n",
    "        # ì´ discriminator ì†ì‹¤\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # -------------------------\n",
    "        #  Generator í•™ìŠµ\n",
    "        # -------------------------\n",
    "        # GeneratorëŠ” ì—¬ëŸ¬ ë²ˆ ì—…ë°ì´íŠ¸\n",
    "        if i % 2 == 0:  # Discriminatorë¥¼ 2íšŒ ì—…ë°ì´íŠ¸ í›„ Generator ì—…ë°ì´íŠ¸\n",
    "            optimizer_g.zero_grad()\n",
    "            fake_output = discriminator(fake_imgs)\n",
    "            g_loss = criterion(fake_output, real_labels)\n",
    "            # fake ì´ë¯¸ì§€ë¥¼ ì§„ì§œë¡œ íŒë³„í•˜ë„ë¡ í•¨\n",
    "            g_loss.backward()\n",
    "            optimizer_g.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f'Epoch [{epoch}/{epochs}], Step [{i}/{len(dataloader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}')\n",
    "\n",
    "        # ì´ë¯¸ì§€ ìƒì„± ë° ì €ì¥ (sample_intervalë§ˆë‹¤)\n",
    "        if (epoch * len(dataloader) + i) % sample_interval == 0:\n",
    "            save_image(fake_imgs.data[:25], f'./output/fake_images_epoch_{epoch+1}_step_{i}.png', nrow=5, normalize=True)\n",
    "\n",
    "# í•™ìŠµ í›„ ìµœì¢… ìƒì„±ëœ ì´ë¯¸ì§€ ì‹œê°í™”\n",
    "z = torch.randn(25, z_dim).to(device)\n",
    "fake_imgs = generator(z)\n",
    "\n",
    "# ìƒì„±ëœ ì´ë¯¸ì§€ ì‹œê°í™”\n",
    "grid_img = torchvision.utils.make_grid(fake_imgs, nrow=5, normalize=True)\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.imshow(grid_img.permute(1, 2, 0).cpu().detach().numpy())\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ë°ì´í„° ë¡œë”© ë° ì „ì²˜ë¦¬\n",
    "- LFW ë°ì´í„°ì…‹ì€ torchvision.datasets.LFWPeople í´ë˜ìŠ¤ë¥¼ í†µí•´ ë¡œë“œë©ë‹ˆë‹¤.\n",
    "ì´ë¯¸ì§€ëŠ” 64x64 í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆë˜ê³ , ToTensor()ë¥¼ ì‚¬ìš©í•´ í…ì„œë¡œ ë³€í™˜ë©ë‹ˆë‹¤. Normalize()ë¡œ í”½ì…€ ê°’ì„ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.\n",
    "\n",
    "5. Generator ëª¨ë¸\n",
    "- GeneratorëŠ” z_dim í¬ê¸°ì˜ ëœë¤ ë…¸ì´ì¦ˆ ë²¡í„°ë¥¼ ì…ë ¥ë°›ì•„ (3, 64, 64) í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì—¬ê¸°ì„œëŠ” FC layersë¡œ êµ¬ì„±ëœ ëª¨ë¸ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "6. Discriminator ëª¨ë¸\n",
    "- DiscriminatorëŠ” ì´ë¯¸ì§€ê°€ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ë¥¼ íŒë³„í•˜ëŠ” ëª¨ë¸ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ëŠ” (3, 64, 64) í¬ê¸°ì´ë¯€ë¡œ ì´ë¥¼ í‰íƒ„í™”í•˜ì—¬ FC layersë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n",
    "- \n",
    "7. í•™ìŠµ ê³¼ì •\n",
    "- Discriminator í•™ìŠµ: ì§„ì§œ ì´ë¯¸ì§€ë¥¼ 1ë¡œ, ê°€ì§œ ì´ë¯¸ì§€ë¥¼ 0ìœ¼ë¡œ íŒë³„í•˜ì—¬ ì†ì‹¤ì„ ê³„ì‚°í•˜ê³ , ê·¸ë¼ë””ì–¸íŠ¸ë¥¼ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤.\n",
    "- Generator í•™ìŠµ: GeneratorëŠ” Discriminatorë¥¼ ì†ì´ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤. ì¦‰, ê°€ì§œ ì´ë¯¸ì§€ê°€ ì§„ì§œë¡œ íŒë³„ë˜ë„ë¡ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "\n",
    "8. ì‹œê°í™”\n",
    "- ê° epochë§ˆë‹¤ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ save_image()ë¡œ ì €ì¥í•©ë‹ˆë‹¤.\n",
    "- í•™ìŠµì´ ì™„ë£Œëœ í›„, ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ matplotlibë¥¼ ì‚¬ìš©í•´ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "  \n",
    "9. ì‹œê°í™” ê²°ê³¼\n",
    "- í•™ìŠµ ì§„í–‰ ì¤‘ì— ìƒì„±ëœ ì´ë¯¸ì§€ëŠ” ./output/ í´ë”ì— ì €ì¥ë©ë‹ˆë‹¤.\n",
    "- í•™ìŠµ í›„ì—ëŠ” matplotlibì„ ì‚¬ìš©í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(z_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 784),\n",
    "            nn.Tanh()  # MNIST ë°ì´í„°ëŠ” ì¼ë°˜ì ìœ¼ë¡œ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = x.reshape(-1, 1, 28, 28)  # 28x28 ì´ë¯¸ì§€ í˜•íƒœë¡œ ì¬êµ¬ì„±\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(784, 128),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)  # ì´ë¯¸ì§€ë¥¼ ì¼ë ¨ì˜ ë²¡í„°ë¡œ í‰íƒ„í™”\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "batch_size = 128\n",
    "z_dim = 100\n",
    "learning_rate = 0.0002\n",
    "num_epochs = 50\n",
    "\n",
    "# ë°ì´í„° ë¡œë”\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # ë°ì´í„°ë¥¼ [-1, 1] ë²”ìœ„ë¡œ ì •ê·œí™”\n",
    "])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "generator = Generator(z_dim)\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n",
    "criterion = nn.BCELoss()\n",
    "g_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# í•™ìŠµ\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, _) in enumerate(train_loader):\n",
    "        b_size = images.size(0)\n",
    "\n",
    "        # ë ˆì´ë¸” ë°ì´í„° ìƒì„±\n",
    "        real_labels = torch.ones(b_size, 1)\n",
    "        fake_labels = torch.zeros(b_size, 1)\n",
    "\n",
    "        # íŒë³„ì í›ˆë ¨\n",
    "        d_optimizer.zero_grad()\n",
    "        outputs = discriminator(images)\n",
    "        d_loss_real = criterion(outputs, real_labels)\n",
    "        real_score = outputs\n",
    "\n",
    "        z = torch.randn(b_size, z_dim)\n",
    "        fake_images = generator(z)\n",
    "        outputs = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(outputs, fake_labels)\n",
    "        fake_score = outputs\n",
    "\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "        d_loss.backward()\n",
    "        d_optimizer.step()\n",
    "\n",
    "        # ìƒì„±ì í›ˆë ¨\n",
    "        g_optimizer.zero_grad()\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        g_optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# GPU ì‚¬ìš© ì„¤ì •\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ìƒì„±ì ëª¨ë¸ ì •ì˜\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 28 * 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z).view(-1, 1, 28, 28)\n",
    "\n",
    "# íŒë³„ì ëª¨ë¸ ì •ì˜\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™” ë° GPUë¡œ ì´ë™\n",
    "generator = Generator().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜ ì„¤ì •\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# í›ˆë ¨ ë£¨í”„\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        imgs = imgs.to(device)  # ë°°ì¹˜ ë°ì´í„°ë¥¼ GPUë¡œ ì´ë™\n",
    "\n",
    "        # ì§„ì§œ ë° ê°€ì§œ ë ˆì´ë¸” ìƒì„±\n",
    "        real_labels = torch.ones(imgs.size(0), 1, device=device)\n",
    "        fake_labels = torch.zeros(imgs.size(0), 1, device=device)\n",
    "\n",
    "        # íŒë³„ì í›ˆë ¨\n",
    "        optimizer_D.zero_grad()\n",
    "        real_outputs = discriminator(imgs)\n",
    "        d_loss_real = criterion(real_outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        z = torch.randn(imgs.size(0), latent_dim, device=device)  # Latent space ë²¡í„°ë¥¼ GPUë¡œ ì´ë™\n",
    "        fake_images = generator(z)\n",
    "        fake_outputs = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "\n",
    "        optimizer_D.step()\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # ìƒì„±ì í›ˆë ¨\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f'Epoch [{epoch}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
    "\n",
    "    # ìƒì„±ëœ ì´ë¯¸ì§€ ì¶œë ¥\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(25, latent_dim, device=device)\n",
    "            # Latent space ë²¡í„°ë¥¼ GPUë¡œ ì´ë™\n",
    "            fake_images = generator(z).detach().cpu()\n",
    "            # ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ CPUë¡œ ì´ë™\n",
    "            fake_images = fake_images.view(-1, 28, 28)\n",
    "            # ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³€í™˜\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            for i in range(25):\n",
    "                plt.subplot(5, 5, i + 1)\n",
    "                plt.imshow(fake_images[i], cmap='gray')\n",
    "                plt.axis('off')  # ì¶• í‘œì‹œ ì œê±°\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "num_epochs = 50\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ìƒì„±ì ëª¨ë¸ ì •ì˜\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 28 * 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z).view(-1, 1, 28, 28)\n",
    "\n",
    "# íŒë³„ì ëª¨ë¸ ì •ì˜\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜ ì„¤ì •\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# í›ˆë ¨ ë£¨í”„\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        # ì§„ì§œ ë° ê°€ì§œ ë ˆì´ë¸” ìƒì„±\n",
    "        real_labels = torch.ones(imgs.size(0), 1)\n",
    "        fake_labels = torch.zeros(imgs.size(0), 1)\n",
    "\n",
    "        # íŒë³„ì í›ˆë ¨\n",
    "        optimizer_D.zero_grad()\n",
    "        real_outputs = discriminator(imgs)\n",
    "        d_loss_real = criterion(real_outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        z = torch.randn(imgs.size(0), latent_dim)\n",
    "        fake_images = generator(z)\n",
    "        fake_outputs = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "\n",
    "        optimizer_D.step()\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # ìƒì„±ì í›ˆë ¨\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f'Epoch [{epoch}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
    "\n",
    "    # ìƒì„±ëœ ì´ë¯¸ì§€ ì¶œë ¥\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(25, latent_dim)\n",
    "            fake_images = generator(z).detach().cpu()\n",
    "            fake_images = fake_images.view(-1, 28, 28)  # ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³€í™˜\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            for i in range(25):\n",
    "                plt.subplot(5, 5, i + 1)\n",
    "                plt.imshow(fake_images[i], cmap='gray')\n",
    "                plt.axis('off')  # ì¶• í‘œì‹œ ì œê±°\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "batch_size = 64\n",
    "latent_dim = 100\n",
    "num_epochs = 100\n",
    "learning_rate = 0.0002\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# ìƒì„±ì ëª¨ë¸ ì •ì˜\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 28 * 28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.model(z).view(-1, 1, 28, 28)\n",
    "\n",
    "# íŒë³„ì ëª¨ë¸ ì •ì˜\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(28 * 28, 512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, img):\n",
    "        return self.model(img)\n",
    "\n",
    "# ëª¨ë¸ ì´ˆê¸°í™”\n",
    "generator = Generator()\n",
    "discriminator = Discriminator()\n",
    "\n",
    "# ì†ì‹¤ í•¨ìˆ˜ ë° ìµœì í™” í•¨ìˆ˜ ì„¤ì •\n",
    "criterion = nn.BCELoss()\n",
    "optimizer_G = optim.Adam(generator.parameters(), lr=learning_rate)\n",
    "optimizer_D = optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "\n",
    "# í›ˆë ¨ ë£¨í”„\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (imgs, _) in enumerate(train_loader):\n",
    "        # ì§„ì§œ ë° ê°€ì§œ ë ˆì´ë¸” ìƒì„±\n",
    "        real_labels = torch.ones(imgs.size(0), 1)\n",
    "        fake_labels = torch.zeros(imgs.size(0), 1)\n",
    "\n",
    "        # íŒë³„ì í›ˆë ¨\n",
    "        optimizer_D.zero_grad()\n",
    "        real_outputs = discriminator(imgs)\n",
    "        d_loss_real = criterion(real_outputs, real_labels)\n",
    "        d_loss_real.backward()\n",
    "\n",
    "        z = torch.randn(imgs.size(0), latent_dim)\n",
    "        fake_images = generator(z)\n",
    "        fake_outputs = discriminator(fake_images.detach())\n",
    "        d_loss_fake = criterion(fake_outputs, fake_labels)\n",
    "        d_loss_fake.backward()\n",
    "\n",
    "        optimizer_D.step()\n",
    "        d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "        # ìƒì„±ì í›ˆë ¨\n",
    "        optimizer_G.zero_grad()\n",
    "        outputs = discriminator(fake_images)\n",
    "        g_loss = criterion(outputs, real_labels)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "    print(f'Epoch [{epoch}/{num_epochs}], d_loss: {d_loss.item():.4f}, g_loss: {g_loss.item():.4f}')\n",
    "\n",
    "    # ìƒì„±ëœ ì´ë¯¸ì§€ ì¶œë ¥\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        with torch.no_grad():\n",
    "            z = torch.randn(25, latent_dim)\n",
    "            fake_images = generator(z).detach().cpu()\n",
    "            fake_images = fake_images.view(-1, 28, 28)  # ì´ë¯¸ì§€ í˜•íƒœë¡œ ë³€í™˜\n",
    "\n",
    "            plt.figure(figsize=(5, 5))\n",
    "            for i in range(25):\n",
    "                plt.subplot(5, 5, i + 1)\n",
    "                plt.imshow(fake_images[i], cmap='gray')\n",
    "                plt.axis('off')  # ì¶• í‘œì‹œ ì œê±°\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **13.3 íŒŒì´í† ì¹˜ í•œêµ­ ì‚¬ìš©ì ì»¤ë®¤ë‹ˆí‹° íŠœí† ë¦¬ì–¼ ì˜ˆì œ ì†Œê°œ**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img width=\"400\" height=\"\" src=\"./image/kr_pytorch.png\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "íŒŒì´í† ì¹˜ í•œêµ­ ì‚¬ìš©ì ëª¨ì„ì€ í•œêµ­ ì‚¬ìš©ìë¥¼ ìœ„í•œ ë¹„ê³µì‹ ì‚¬ìš©ì ëª¨ì„ìœ¼ë¡œ, í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•˜ì‹œëŠ” ë§ì€ ë¶„ë“¤ê»˜ PyTorchë¥¼ ì†Œê°œí•˜ê³  í•¨ê»˜ ë°°ìš°ë©° ì„±ì¥í•˜ëŠ” ê²ƒì„ ëª©í‘œë¡œ í•˜ê³  ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "Google Colabì—ì„œ ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•˜ì‹¤ ë•Œì—ëŠ” \n",
    "https://tutorials.pytorch.kr/beginner/colab ë¥¼ ì°¸ê³ í•˜ì„¸ìš”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# DCGAN íŠœí† ë¦¬ì–¼\n",
    "\n",
    "**ì €ì**: [Nathan Inkawhich](https://github.com/inkawhich)\n",
    "**ë²ˆì—­**: [ì¡°ë¯¼ì„±](https://github.com/miNept)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê°œìš”\n",
    "\n",
    "ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ì˜ˆì œë¥¼ í†µí•´ DCGANì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ìš°ë¦¬ëŠ” ì‹¤ì œ ìœ ëª…ì¸ë“¤ì˜ ì‚¬ì§„ë“¤ë¡œ ì ëŒ€ì  ìƒì„± ì‹ ê²½ë§(GAN)ì„ í•™ìŠµì‹œì¼œ,\n",
    "ìƒˆë¡œìš´ ìœ ëª…ì¸ì˜ ì‚¬ì§„ì„ ë§Œë“¤ì–´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "ì‚¬ìš©í•  ëŒ€ë¶€ë¶„ì˜ ì½”ë“œëŠ” [pytorch/examples](https://github.com/pytorch/examples)_ ì˜ DCGAN êµ¬í˜„ì—ì„œ ê°€ì ¸ì™”ìœ¼ë©°,\n",
    "ë³¸ ë¬¸ì„œëŠ” êµ¬í˜„ì— ëŒ€í•œ ì„¤ëª…ê³¼ í•¨ê»˜, ì–´ì§¸ì„œ ì´ ëª¨ë¸ì´ ì‘ë™í•˜ëŠ”ì§€ì— ëŒ€í•´ ì„¤ëª…ì„ í•´ì¤„ ê²ƒì…ë‹ˆë‹¤.\n",
    "ì²˜ìŒ ì½ì—ˆì„ë•ŒëŠ”, ì‹¤ì œë¡œ ëª¨ë¸ì— ë¬´ìŠ¨ì¼ì´ ì¼ì–´ë‚˜ê³  ìˆëŠ”ì§€ì— ëŒ€í•´ ì´í•´í•˜ëŠ” ê²ƒì´ ì¡°ê¸ˆ ì‹œê°„ì„ ì†Œìš”í•  ìˆ˜ ìˆìœ¼ë‚˜,\n",
    "ê·¸ë˜ë„ GANì— ëŒ€í•œ ì‚¬ì „ì§€ì‹ì´ í•„ìš”í•˜ì§€ëŠ” ì•Šìœ¼ë‹ˆ ê±±ì •í•˜ì§€ ì•Šìœ¼ì…”ë„ ë©ë‹ˆë‹¤.\n",
    "ì¶”ê°€ë¡œ, GPU 1-2ê°œë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì‹œê°„ì ˆì•½ì— ë„ì›€ì´ ë ê²ë‹ˆë‹¤. ê·¸ëŸ¼ ì²˜ìŒë¶€í„° ì²œì²œíˆ ì‹œì‘í•´ë´…ì‹œë‹¤!\n",
    "\n",
    "## ì ëŒ€ì  ìƒì„± ì‹ ê²½ë§(Generative Adversarial Networks)\n",
    "\n",
    "### ê·¸ë˜ì„œ GANì´ ë­˜ê¹Œìš”?\n",
    "\n",
    "GANì´ë€ í•™ìŠµ ë°ì´í„°ë“¤ì˜ ë¶„í¬ë¥¼ í•™ìŠµí•œ ë’¤, ë™ì¼í•œ ë¶„í¬ë¥¼ ê°–ëŠ” ìƒˆë¡œìš´ ë°ì´í„°ë¥¼\n",
    "ìƒì„±í•˜ë„ë¡ ë”¥ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” í”„ë ˆì„ì›Œí¬ì…ë‹ˆë‹¤.\n",
    "GANì€ 2014ë…„ Ian Goodfellowê°€ ê°œë°œí–ˆìœ¼ë©°,\n",
    "[Generative Adversarial Nets](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)_ ë…¼ë¬¸ì—ì„œ\n",
    "ì²˜ìŒ ì†Œê°œë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "GANì€ *ìƒì„±ì(Generator)* ì™€ *êµ¬ë¶„ì(Discriminator)* ë¼ëŠ” ë‘ ê°œì˜ ì„œë¡œ\n",
    "ë‹¤ë¥¸(distinct) ëª¨ë¸ë“¤ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n",
    "ìƒì„±ì(Generator)ì˜ ì—­í• ì€ í•™ìŠµí•œ ì´ë¯¸ì§€ë“¤ê³¼ ê°™ì•„ ë³´ì´ëŠ” `ê°€ì§œ(fake)`\n",
    "ì´ë¯¸ì§€ë¥¼ ë§Œë“œëŠ” ê²ƒì´ê³ , êµ¬ë¶„ì(Discriminator)ëŠ” ì´ë¯¸ì§€ë¥¼ ë³´ê³  ì´ê²ƒì´\n",
    "ì‹¤ì œ í•™ìŠµ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¨ ê²ƒì¸ì§€, ë˜ëŠ” ìƒì„±ìì— ì˜í•´ ë§Œë“¤ì–´ì§„ ê°€ì§œ\n",
    "ì´ë¯¸ì§€ì¸ì§€ íŒë³„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "ëª¨ë¸ì„ í•™ìŠµí•˜ëŠ” ë™ì•ˆ ìƒì„±ìëŠ” ë” ì§„ì§œ ê°™ì€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ë‚´ë©°\n",
    "êµ¬ë¶„ìë¥¼ ì†ì´ë ¤ í•˜ê³ , êµ¬ë¶„ìëŠ” ì§„ì§œ ì´ë¯¸ì§€ì™€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ë” ì •í™•íˆ\n",
    "íŒë³„í•  ìˆ˜ ìˆë„ë¡ ë…¸ë ¥í•©ë‹ˆë‹¤.\n",
    "ì´ëŸ¬í•œ ê³¼ì •ì€ ìƒì„±ìê°€ ë§ˆì¹˜ í•™ìŠµ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¨ ê²ƒì²˜ëŸ¼ ë³´ì´ëŠ”\n",
    "ì™„ë²½í•œ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•´ë‚´ê³ , íŒë³„ìëŠ” í•­ìƒ 50%ì˜ ì‹ ë¢°ë„ë¡œ\n",
    "ìƒì„±ìì˜ ì¶œë ¥ì´ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ íŒë³„í•  ìˆ˜ ìˆì„ ë•Œ ê· í˜• ìƒíƒœ(equilbrium)ì—\n",
    "ë„ë‹¬í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ê·¸ëŸ¼ ì´ì œë¶€í„° ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œ ì‚¬ìš©í•  í‘œê¸°ë“¤ì„ êµ¬ë¶„ìë¶€í„° ì •ì˜í•´ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "$x$ ëŠ” ì´ë¯¸ì§€ë¡œ í‘œí˜„ë˜ëŠ” ë°ì´í„°ë¼ê³  í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "$D(x)$ ëŠ” êµ¬ë¶„ìì˜ ì‹ ê²½ë§ì„ ë‚˜íƒ€ë‚´ë©°, ì‹¤ì œ í•™ìŠµ ë°ì´í„°ì—ì„œ ê°€ì ¸ì˜¨\n",
    "$x$ ë¥¼ í†µê³¼ì‹œì¼œ í™•ë¥  ê°’(scalar)ì„ ê²°ê³¼ë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "ì—¬ê¸°ì—ì„œëŠ” ì´ë¯¸ì§€ ë°ì´í„°ë¥¼ ë‹¤ë£¨ê³  ìˆìœ¼ë¯€ë¡œ,\n",
    "$D(x)$ ì˜ ì…ë ¥ìœ¼ë¡œëŠ” 3x64x64 í¬ê¸°ì˜ CHW ì´ë¯¸ì§€ê°€ ì£¼ì–´ì§‘ë‹ˆë‹¤.\n",
    "ì§ê´€ì ìœ¼ë¡œ $D(x)$ ëŠ” $x$ ê°€ í•™ìŠµ ë°ì´í„°ì—ì„œ ê°€ì ¸ì™”ì„ ë•Œ ì¶œë ¥ì´ í¬ê³ (HIGH),\n",
    "ìƒì„±ìê°€ ë§Œë“¤ì–´ë‚¸ $x$ ì¼ ë•ŒëŠ” ì‘ì„(LOW) ê²ƒì…ë‹ˆë‹¤.\n",
    "$D(x)$ ëŠ” ì „í†µì ì¸ ì´ì§„ ë¶„ë¥˜ê¸°(binary classification)ë¡œë„ ìƒê°í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ë²ˆì—” ìƒì„±ìì˜ í‘œê¸°ë“¤ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤. $z$ ë¥¼ ì •ê·œë¶„í¬ì—ì„œ ë½‘ì€\n",
    "ì ì¬ê³µê°„ ë²¡í„°(laten space vector)ë¼ê³  í•˜ê² ìŠµë‹ˆë‹¤\n",
    "(ë²ˆì—­ ì£¼. laten space vectorëŠ” ì‰½ê²Œ ìƒê°í•´ ì •ê·œë¶„í¬ë¥¼ ë”°ë¥´ëŠ” nê°œì˜ ì›ì†Œë¥¼ ê°€ì§„ vectorë¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ë‹¤ë¥´ê²Œ ì–˜ê¸°í•˜ë©´ ì •ê·œë¶„í¬ì—ì„œ nê°œì˜ ì›ì†Œë¥¼ ì¶”ì¶œí•œ ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤). $G(z)$ ëŠ” $z$\n",
    "ë²¡í„°ë¥¼ ì›í•˜ëŠ” ë°ì´í„° ì°¨ì›ìœ¼ë¡œ ëŒ€ì‘ì‹œí‚¤ëŠ” ì‹ ê²½ë§ìœ¼ë¡œ ë‘˜ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ $G$ ì˜ ëª©ì ì€ $p_{data}$\n",
    "ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ” í•™ìŠµ ë°ì´í„°ë“¤ì˜ ë¶„í¬ë¥¼ ì¶”ì •í•˜ì—¬, ëª¨ì‚¬í•œ $p_g$ ì˜ ë¶„í¬ë¥¼ ì´ìš©í•´ ê°€ì§œ ë°ì´í„°ë“¤ì„ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ì–´ì„œ, $D(G(z))$ ëŠ” $G$ ê°€ ì¶œë ¥í•œ ê²°ê³¼ë¬¼ì´ ì‹¤ì œ ì´ë¯¸ì§€ ì—¬ë¶€ë¥¼\n",
    "ë‚˜íƒ€ë‚´ëŠ” 0~1 ì‚¬ì´ì˜ í™•ë¥  ê°’(scalar)ì…ë‹ˆë‹¤.\n",
    "[Goodfellowì˜ ë…¼ë¬¸](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)_\n",
    "ì— ê¸°ìˆ ë˜ì–´ ìˆë“¯ì´, $D$ ì™€ $G$ ëŠ” ì¼ì¢…ì˜ ìµœëŒ€-ìµœì†Œ ê²Œì„(minimax game)ì„\n",
    "í•˜ê³  ìˆëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤. ì´ëŠ” $D$ ëŠ” ì´ë¯¸ì§€ê°€ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ ì—¬ë¶€ë¥¼ íŒë³„í•˜ëŠ” í™•ë¥ ì¸\n",
    "$logD(x)$ ë¥¼ ìµœëŒ€í™”í•˜ë ¤ê³  í•˜ê³ , $G$ ëŠ” $D$ ê°€ ê°€ì§œë¼ê³  íŒë³„í•  í™•ë¥ ì¸ $log(1-D(G(z)))$ ë¥¼\n",
    "ìµœì†Œí™”ì‹œí‚¤ë ¤ê³  í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "ë…¼ë¬¸ì— ë”°ë¥´ë©´, GANì˜ ì†ì‹¤í•¨ìˆ˜ëŠ” ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.\n",
    "\n",
    "\\begin{align}\\underset{G}{\\text{min}} \\underset{D}{\\text{max}}V(D,G) = \\mathbb{E}_{x\\sim p_{data}(x)}\\big[logD(x)\\big] + \\mathbb{E}_{z\\sim p_{z}(z)}\\big[log(1-D(G(z)))\\big]\\end{align}\n",
    "\n",
    "ì´ë¡ ì ìœ¼ë¡œëŠ”, ì´ ìµœëŒ€-ìµœì†Œ ê²Œì„ì˜ ë‹µ(solution)ì€ $p_g = p_{data}$\n",
    "ì¼ ë•Œì´ë©°, ì´ ë•Œ êµ¬ë¶„ìëŠ” ì…ë ¥ì´ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ë¥¼ ë¬´ì‘ìœ„ë¡œ ì¶”ì¸¡í•˜ê²Œ\n",
    "ë©ë‹ˆë‹¤. í•˜ì§€ë§Œ GANì˜ ìˆ˜ë ´ ì´ë¡ (convergence theory)ì— ëŒ€í•´ì„œëŠ” ì•„ì§ë„\n",
    "í™œë°œíˆ ì—°êµ¬ê°€ ì§„í–‰ ì¤‘ì´ë©°, ì‹¤ì œ ëª¨ë¸ë“¤ì„ í•™ìŠµí•  ë•Œì—ëŠ” í•­ìƒ ì´ëŸ¬í•œ\n",
    "ì´ë¡ ì ì¸ ìµœì  ìƒíƒœì— ë„ë‹¬í•˜ì§€ëŠ” ëª»í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ê·¸ë ‡ë‹¤ë©´ DCGANì€ ë­˜ê¹Œìš”?\n",
    "\n",
    "DCGANì€ ìœ„ì—ì„œ ê¸°ìˆ í•œ GANì—ì„œ ì§ì ‘ì ìœ¼ë¡œ íŒŒìƒëœ ëª¨ë¸ë¡œ, ìƒì„±ìì™€ êµ¬ë¶„ìì—ì„œ\n",
    "í•©ì„±ê³± ì‹ ê²½ë§(convolution)ê³¼ ì „ì¹˜ í•©ì„±ê³± ì‹ ê²½ë§(convolution-transpose)ì„ ì‚¬ìš©í–ˆë‹¤ëŠ” ê²ƒì´ ì°¨ì´ì ì…ë‹ˆë‹¤\n",
    "Radfordì™€ ê·¸ ì™¸ê°€ ì €ìˆ í•œ [Unsupervised Representation Learning With\n",
    "Deep Convolutional Generative Adversarial\n",
    "Networks](https://arxiv.org/pdf/1511.06434.pdf)_ ë…¼ë¬¸ì—ì„œ ì²˜ìŒ ëª¨ë¸ì´ ì†Œê°œë˜ì—ˆê³ , ì§€ê¸ˆì€ ëŒ€ë¶€ë¶„ì˜ GANëª¨ë¸ì´\n",
    "DCGANì„ ê¸°ë°˜ìœ¼ë¡œ ë§Œë“¤ì–´ì§€ëŠ” ì¤‘ì…ë‹ˆë‹¤. ì´ì „ GANê³¼ ëª¨ë¸ì˜ êµ¬ì¡°ê°€ ì‹¤ì œë¡œ ì–´ë–»ê²Œ ë‹¤ë¥¸ì§€ í™•ì¸ì„ í•´ë³´ìë©´, ë¨¼ì € êµ¬ë¶„ìì—ì„œëŠ”\n",
    "[convolution](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d)_\n",
    "ê³„ì¸µ, [batch\n",
    "norm](https://pytorch.org/docs/stable/nn.html#torch.nn.BatchNorm2d)_\n",
    "ê³„ì¸µ, ê·¸ë¦¬ê³ \n",
    "[LeakyReLU](https://pytorch.org/docs/stable/nn.html#torch.nn.LeakyReLU)_\n",
    "í™œì„±í•¨ìˆ˜ê°€ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. í´ë˜ì‹í•œ GANê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, êµ¬ë¶„ìì˜ ì…ë ¥ ë°ì´í„°ëŠ” 3x64x64 ì˜ ì´ë¯¸ì§€ì´ê³ ,\n",
    "ì¶œë ¥ê°’ì€ ì…ë ¥ ë°ì´í„°ê°€ ì‹¤ì œ ë°ì´í„°ì¼ 0~1ì‚¬ì´ì˜ í™•ë¥ ê°’ì…ë‹ˆë‹¤.\n",
    "ë‹¤ìŒìœ¼ë¡œ, ìƒì„±ìëŠ”\n",
    "[convolutional-transpose](https://pytorch.org/docs/stable/nn.html#torch.nn.ConvTranspose2d)_\n",
    "ê³„ì¸µ, ë°°ì¹˜ ì •ê·œí™”(batch norm) ê³„ì¸µ, ê·¸ë¦¬ê³ \n",
    "[ReLU](https://pytorch.org/docs/stable/nn.html#relu)_ í™œì„±í•¨ìˆ˜ê°€ ì‚¬ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.\n",
    "ì…ë ¥ê°’ì€ ì—­ì‹œë‚˜ ì •ê·œë¶„í¬ì—ì„œ ì¶”ì¶œí•œ ì ì¬ê³µê°„ ë²¡í„° $z$ ì´ê³ , ì¶œë ¥ê°’ì€ 3x64x64 RGB ì´ë¯¸ì§€ì…ë‹ˆë‹¤.\n",
    "ì´ ë•Œ, ì „ì¹˜ í•©ì„±ê³± ê³„ì¸µ(strided conv-transpose layer)ì€ ì ì¬ê³µê°„ ë²¡í„°ë¡œ í•˜ì—¬ê¸ˆ ì´ë¯¸ì§€ì™€ ê°™ì€ ì°¨ì›ì„ ê°–ë„ë¡ ë³€í™˜ì‹œì¼œì£¼ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.\n",
    "(ë²ˆì—­ ì£¼. ì „ì¹˜ í•©ì„±ê³± ì‹ ê²½ë§ì€ í•©ì„±ê³± ì‹ ê²½ë§ì˜ ë°˜ëŒ€ì ì¸ ê°œë…ì´ë¼ ì´í•´í•˜ë©´ ì‰½ìŠµë‹ˆë‹¤. ì…ë ¥ëœ ì‘ì€ CHW ë°ì´í„°ë¥¼ ê°€ì¤‘ì¹˜ë“¤ì„ ì´ìš©í•´ ë” í° CHWë¡œ ì—…ìƒ˜í”Œë§í•´ì£¼ëŠ” ê³„ì¸µì…ë‹ˆë‹¤.)\n",
    "ë…¼ë¬¸ì—ì„œëŠ” ê°ì¢… ìµœì í™” ë°©ë²•ì´ë‚˜ ì†ì‹¤í•¨ìˆ˜ì˜ ê³„ì‚°, ëª¨ë¸ì˜ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” ë°©ë²•ë“±ì— ê´€í•œ ì¶”ê°€ì ì¸ ì •ë³´ë“¤ë„ ì ì–´ë‘ì—ˆëŠ”ë°,\n",
    "ì´ ë¶€ë¶„ì€ ë‹¤ìŒ ì„¹ì…˜ì—ì„œ ì„¤ëª…í•˜ë„ë¡ í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# ì½”ë“œ ì‹¤í–‰ê²°ê³¼ì˜ ë™ì¼ì„±ì„ ìœ„í•´ ë¬´ì‘ìœ„ ì‹œë“œë¥¼ ì„¤ì •í•©ë‹ˆë‹¤\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # ë§Œì¼ ìƒˆë¡œìš´ ê²°ê³¼ë¥¼ ì›í•œë‹¤ë©´ ì£¼ì„ì„ ì—†ì• ë©´ ë©ë‹ˆë‹¤\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "torch.use_deterministic_algorithms(True) # ê²°ê³¼ ì¬í˜„ì„ ìœ„í•´ í•„ìš”í•©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì„¤ì • ê°’\n",
    "\n",
    "ëª‡ ê°€ì§€ ì„¤ì • ê°’ë“¤ì„ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤:\n",
    "\n",
    "-  ``dataroot`` - ë°ì´í„°ì…‹ í´ë”ì˜ ê²½ë¡œì…ë‹ˆë‹¤. ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œëŠ” ë‹¤ìŒ ì„¹ì…˜ì—ì„œ\n",
    "   ë” ìì„¸íˆ ì„¤ëª…í•˜ê² ìŠµë‹ˆë‹¤.\n",
    "-  ``workers`` - ``DataLoader`` ì—ì„œ ë°ì´í„°ë¥¼ ë¶ˆëŸ¬ì˜¬ ë•Œ ì‚¬ìš©í•  ì›Œì»¤ ì“°ë ˆë“œì˜\n",
    "   ìˆ˜ì…ë‹ˆë‹¤.\n",
    "-  ``batch_size`` - í•™ìŠµì— ì‚¬ìš©í•  ë°°ì¹˜ í¬ê¸°ì…ë‹ˆë‹¤. DCGANì—ì„œëŠ” ë°°ì¹˜ í¬ê¸°ë¥¼\n",
    "   128ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.\n",
    "-  ``image_size`` - í•™ìŠµì— ì‚¬ìš©í•˜ëŠ” ì´ë¯¸ì§€ì˜ í¬ê¸°ì…ë‹ˆë‹¤.\n",
    "   ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” 64x64ì˜ í¬ê¸°ë¥¼ ê¸°ë³¸ìœ¼ë¡œ í•˜ë‚˜, ë§Œì¼ ë‹¤ë¥¸ í¬ê¸°ì˜ ì´ë¯¸ì§€ë¥¼\n",
    "   ì‚¬ìš©í•œë‹¤ë©´ Dì™€ Gì˜ êµ¬ì¡° ë˜í•œ ë³€ê²½ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "   ì´ì— ëŒ€í•´ì„œëŠ” [ì—¬ê¸°](https://github.com/pytorch/examples/issues/70)_ ë¥¼ ì°¸ê³ í•˜ì—¬\n",
    "   ë” ìì„¸í•œ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "-  ``nc`` - ì…ë ¥ ì´ë¯¸ì§€ì˜ ìƒ‰ìƒì˜ ì±„ë„ ìˆ˜ì…ë‹ˆë‹¤. RGB ì»¬ëŸ¬ ì´ë¯¸ì§€ì˜ ê²½ìš°\n",
    "   ì´ ê°’ì€ 3ì…ë‹ˆë‹¤.\n",
    "-  ``nz`` - ì ì¬ê³µê°„ ë²¡í„°ì˜ ì›ì†Œë“¤ì˜ ìˆ˜ì…ë‹ˆë‹¤.\n",
    "-  ``ngf`` - ìƒì„±ìë¥¼ í†µê³¼í•  ë•Œ ë§Œë“¤ì–´ì§ˆ íŠ¹ì§• ë°ì´í„°ì˜ ì±„ë„ ìˆ˜ì…ë‹ˆë‹¤.\n",
    "-  ``ndf`` - êµ¬ë¶„ìë¥¼ í†µê³¼í•  ë•Œ ë§Œë“¤ì–´ì§ˆ íŠ¹ì§• ë°ì´í„°ì˜ ì±„ë„ ìˆ˜ì…ë‹ˆë‹¤.\n",
    "-  ``num_epochs`` - í•™ìŠµì‹œí‚¬ ì—í­(epoch) ìˆ˜ì…ë‹ˆë‹¤. í•™ìŠµì„\n",
    "   ê¸¸ê²Œí•˜ëŠ” ê²½ìš° ëŒ€ë¶€ë¶„ ì¢‹ì€ ê²°ê³¼ë¥¼ ë³´ì´ì§€ë§Œ, ì´ëŸ¬í•œ ê²½ìš° ì‹œê°„ ë˜í•œ\n",
    "   ì˜¤ë˜ ê±¸ë¦½ë‹ˆë‹¤.\n",
    "-  ``lr`` - ëª¨ë¸ì˜ í•™ìŠµë¥ (learning rate)ì…ë‹ˆë‹¤. DCGAN ë…¼ë¬¸ì—ì„œì™€ ê°™ì´ 0.0002ë¡œ\n",
    "   ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "-  ``beta1`` - Adam ì˜µí‹°ë§ˆì´ì €ì—ì„œ ì‚¬ìš©í•  beta1 í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°’ì…ë‹ˆë‹¤.\n",
    "   ë…¼ë¬¸ì—ì„œì™€ ê°™ì´ 0.5ë¡œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.\n",
    "-  ``ngpu`` - ì‚¬ìš© ê°€ëŠ¥í•œ GPUì˜ ê°œìˆ˜ì…ë‹ˆë‹¤. 0ì¸ ê²½ìš°ì—ëŠ” ì½”ë“œëŠ” CPUì—ì„œ ë™ì‘í•©ë‹ˆë‹¤.\n",
    "   ë§Œì•½ ì´ ê°’ì´ 0ë³´ë‹¤ í° ê²½ìš°ì—ëŠ” ì£¼ì–´ì§„ ìˆ˜ ë§Œí¼ì˜ GPUë¥¼ ì‚¬ìš©í•˜ì—¬ í•™ìŠµì„\n",
    "   ì§„í–‰í•©ë‹ˆë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„°ì…‹ì˜ ê²½ë¡œ\n",
    "dataroot = \"data/celeba\"\n",
    "\n",
    "# dataloaderì—ì„œ ì‚¬ìš©í•  ì“°ë ˆë“œ ìˆ˜\n",
    "workers = 2\n",
    "\n",
    "# ë°°ì¹˜ í¬ê¸°\n",
    "batch_size = 128\n",
    "\n",
    "# ì´ë¯¸ì§€ì˜ í¬ê¸°ì…ë‹ˆë‹¤. ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë³€í™˜í•˜ì—¬ 64ë¡œ í¬ê¸°ê°€ í†µì¼ë©ë‹ˆë‹¤.\n",
    "image_size = 64\n",
    "\n",
    "# ì´ë¯¸ì§€ì˜ ì±„ë„ ìˆ˜ë¡œ, RGB ì´ë¯¸ì§€ì´ê¸° ë•Œë¬¸ì— 3ìœ¼ë¡œ ì„¤ì •í•©ë‹ˆë‹¤.\n",
    "nc = 3\n",
    "\n",
    "# ì ì¬ê³µê°„ ë²¡í„°ì˜ í¬ê¸° (ì˜ˆ. ìƒì„±ìì˜ ì…ë ¥ê°’ í¬ê¸°)\n",
    "nz = 100\n",
    "\n",
    "# ìƒì„±ìë¥¼ í†µê³¼í•˜ëŠ” íŠ¹ì§• ë°ì´í„°ë“¤ì˜ ì±„ë„ í¬ê¸°\n",
    "ngf = 64\n",
    "\n",
    "# êµ¬ë¶„ìë¥¼ í†µê³¼í•˜ëŠ” íŠ¹ì§• ë°ì´í„°ë“¤ì˜ ì±„ë„ í¬ê¸°\n",
    "ndf = 64\n",
    "\n",
    "# í•™ìŠµí•  ì—í­ ìˆ˜\n",
    "num_epochs = 5\n",
    "\n",
    "# ì˜µí‹°ë§ˆì´ì €ì˜ í•™ìŠµë¥ \n",
    "lr = 0.0002\n",
    "\n",
    "# Adam ì˜µí‹°ë§ˆì´ì €ì˜ beta1 í•˜ì´í¼íŒŒë¼ë¯¸í„°\n",
    "beta1 = 0.5\n",
    "\n",
    "# ì‚¬ìš©ê°€ëŠ¥í•œ gpu ë²ˆí˜¸. CPUë¥¼ ì‚¬ìš©í•´ì•¼ í•˜ëŠ”ê²½ìš° 0ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ë°ì´í„°\n",
    "\n",
    "ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œ ì‚¬ìš©í•  ë°ì´í„°ëŠ” [Celeb-A Faces\n",
    "dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)_ ë¡œ, í•´ë‹¹ ë§í¬ë¥¼ ì´ìš©í•˜ê±°ë‚˜ [Google\n",
    "Drive](https://drive.google.com/drive/folders/0B7EVK8r0v71pTUZsaXdaSnZBZzg)_ ì—ì„œ ë°ì´í„°ë¥¼ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë°ì´í„°ë¥¼ ë°›ìœ¼ë©´ ``img_align_celeba.zip`` ë¼ëŠ” íŒŒì¼ì„ ë³´ê²Œë  ê²ë‹ˆë‹¤. \n",
    "\n",
    "ë‹¤ìš´ë¡œë“œê°€ ëë‚˜ë©´\n",
    "``celeba`` ì´ë¼ëŠ” í´ë”ë¥¼ ìƒˆë¡œ ë§Œë“¤ê³ , í•´ë‹¹ í´ë”ì— í•´ë‹¹ zip íŒŒì¼ì„ ì••ì¶•í•´ì œ í•´ì£¼ì‹œë©´ ë©ë‹ˆë‹¤.\n",
    "\n",
    "ì••ì¶• í•´ì œ í›„, ìœ„ì—ì„œ ì •ì˜í•œ ``dataroot`` ë³€ìˆ˜ì— ë°©ê¸ˆ ë§Œë“  ``celeba`` í´ë”ì˜ ê²½ë¡œë¥¼ ë„£ì–´ì£¼ì„¸ìš”.\n",
    "\n",
    "ìœ„ì˜ ì‘ì—…ì´ ëë‚˜ë©´ ``celeba`` í´ë”ì˜ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤:\n",
    "\n",
    "```sh\n",
    "/path/to/celeba\n",
    "    -> img_align_celeba\n",
    "        -> 188242.jpg\n",
    "        -> 173822.jpg\n",
    "        -> 284702.jpg\n",
    "        -> 537394.jpg\n",
    "           ...\n",
    "```\n",
    "ì´ ê³¼ì •ë“¤ì€ í”„ë¡œê·¸ë¨ì´ ì •ìƒì ìœ¼ë¡œ êµ¬ë™í•˜ê¸° ìœ„í•´ì„œëŠ” ì¤‘ìš”í•œ ë¶€ë¶„ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ë•Œ ``celeba`` í´ë” ì•ˆì— ë‹¤ì‹œ í´ë”ë¥¼ ë‘ëŠ” ì´ìœ ëŠ”,\n",
    "``ImageFolder`` í´ë˜ìŠ¤ê°€ ë°ì´í„°ì…‹ì˜ ìµœìƒìœ„ í´ë”ì— ì„œë¸Œí´ë”ë¥¼ ìš”êµ¬í•˜ê¸° ë•Œë¬¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "ì´ì œ ``Dataset`` ê³¼ ``DataLoader`` ì˜ ì„¤ì •ì„ ëëƒˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìµœì¢…ì ìœ¼ë¡œ í•™ìŠµ ë°ì´í„°ë“¤ì„ ì‹œê°í™”í•´ë´…ì‹œë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìš°ë¦¬ê°€ ì„¤ì •í•œ ëŒ€ë¡œ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì„ ë¶ˆëŸ¬ì™€ ë´…ì‹œë‹¤\n",
    "# ë¨¼ì € ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.Resize(image_size),\n",
    "                                transforms.CenterCrop(image_size),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "# dataloaderë¥¼ ì •ì˜í•´ë´…ì‹œë‹¤\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                            shuffle=True, num_workers=workers)\n",
    "\n",
    "# GPU ì‚¬ìš©ì—¬ë¶€ë¥¼ ê²°ì •í•´ ì¤ë‹ˆë‹¤\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# í•™ìŠµ ë°ì´í„°ë“¤ ì¤‘ ëª‡ê°€ì§€ ì´ë¯¸ì§€ë“¤ì„ í™”ë©´ì— ë„ì›Œë´…ì‹œë‹¤\n",
    "real_batch = next(iter(dataloader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## êµ¬í˜„\n",
    "\n",
    "ëª¨ë¸ì˜ ì„¤ì •ê°’ë“¤ê³¼ ë°ì´í„°ë“¤ì´ ì¤€ë¹„ë˜ì—ˆê¸° ë•Œë¬¸ì—, ë“œë””ì–´ ëª¨ë¸ì˜ êµ¬í˜„ìœ¼ë¡œ\n",
    "ë“¤ì–´ê°ˆ ìˆ˜ ìˆì„ ê²ƒ ê°™ìŠµë‹ˆë‹¤. \n",
    "\n",
    "ë¨¼ì € ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”ì— ëŒ€í•´ ì´ì•¼ê¸° í•´ë³´ê³ ,\n",
    "ìˆœì„œëŒ€ë¡œ ìƒì„±ì, êµ¬ë¶„ì, ì†ì‹¤ í•¨ìˆ˜, í•™ìŠµ ë°©ë²•ë“¤ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.\n",
    "\n",
    "### ê°€ì¤‘ì¹˜ ì´ˆê¸°í™”\n",
    "\n",
    "DCGAN ë…¼ë¬¸ì—ì„œëŠ”, í‰ê· ì´ 0( ``mean=0`` )ì´ê³  ë¶„ì‚°ì´ 0.02( ``stdev=0.02`` )ì¸\n",
    "ì •ê·œë¶„í¬ì„ ì‹œìš©í•´, êµ¬ë¶„ìì™€ ìƒì„±ì ëª¨ë‘ ë¬´ì‘ìœ„ ì´ˆê¸°í™”ë¥¼ ì§„í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ë‹¤ê³  í•©ë‹ˆë‹¤.\n",
    "\n",
    "``weights_init`` í•¨ìˆ˜ëŠ” ë§¤ê°œë³€ìˆ˜ë¡œ ëª¨ë¸ì„ ì…ë ¥ë°›ì•„,\n",
    "ëª¨ë“  í•©ì„±ê³± ê³„ì¸µ, ì „ì¹˜ í•©ì„±ê³± ê³„ì¸µ, ë°°ì¹˜ ì •ê·œí™” ê³„ì¸µì„, ìœ„ì—ì„œ ë§í•œ ì¡°ê±´ëŒ€ë¡œ\n",
    "ê°€ì¤‘ì¹˜ë“¤ì„ ë‹¤ì‹œ ì´ˆê¸°í™” ì‹œí‚µë‹ˆë‹¤. \n",
    "\n",
    "ì´ í•¨ìˆ˜ëŠ” ëª¨ë¸ì´ ë§Œë“¤ì–´ì§€ì ë§ˆì ë°”ë¡œ ì ìš©ì„ ì‹œí‚¤ê²Œ ë©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ``netG`` ì™€ ``netD`` ì— ì ìš©ì‹œí‚¬ ì»¤ìŠ¤í…€ ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” í•¨ìˆ˜\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ìƒì„±ì\n",
    "\n",
    "ìƒì„±ì $G$ ëŠ” ì ì¬ ê³µê°„ ë²¡í„° $z$ ë¥¼, ë°ì´í„° ê³µê°„ìœ¼ë¡œ\n",
    "ë³€í™˜ì‹œí‚¤ë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤. ìš°ë¦¬ì—ê²Œ ë°ì´í„°ë¼ í•¨ì€ ì´ë¯¸ì§€ì´ê¸° ë•Œë¬¸ì—,\n",
    "$z$ ë¥¼ ë°ì´í„°ê³µê°„ìœ¼ë¡œ ë³€í™˜í•œë‹¤ëŠ” ëœ»ì€, í•™ìŠµì´ë¯¸ì§€ì™€ ê°™ì€ ì‚¬ì´ì¦ˆë¥¼ ê°€ì§„\n",
    "RGB ì´ë¯¸ì§€ë¥¼ ìƒì„±í•˜ëŠ”ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤ (ì˜ˆ.Â 3x64x64).\n",
    "ì‹¤ì œ ëª¨ë¸ì—ì„œëŠ” ìŠ¤íŠ¸ë¼ì´ë“œ(stride) 2ë¥¼ ê°€ì§„ ì „ì¹˜ í•©ì„±ê³± ê³„ì¸µë“¤ì„ ì´ì–´ì„œ êµ¬ì„±í•˜ëŠ”ë°,\n",
    "ê° ì „ì¹˜ í•©ì„±ê³± ê³„ì¸µ í•˜ë‚˜ë‹¹ 2ì°¨ì› ë°°ì¹˜ ì •ê·œí™” ê³„ì¸µê³¼ relu í™œì„±í•¨ìˆ˜ë¥¼ í•œ ìŒìœ¼ë¡œ ë¬¶ì–´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "ìƒì„±ìì˜ ë§ˆì§€ë§‰ ì¶œë ¥ ê³„ì¸µì—ì„œëŠ” ë°ì´í„°ë¥¼ tanh í•¨ìˆ˜ì— í†µê³¼ì‹œí‚¤ëŠ”ë°,\n",
    "ì´ëŠ” ì¶œë ¥ ê°’ì„ $[-1,1]$ ì‚¬ì´ì˜ ë²”ìœ„ë¡œ ì¡°ì •í•˜ê¸° ìœ„í•´ì„œ ì…ë‹ˆë‹¤.\n",
    "ì´ë•Œ ë°°ì¹˜ ì •ê·œí™” ê³„ì¸µì„ ì£¼ëª©í•  í•„ìš”ê°€ ìˆëŠ”ë°, DCGAN ë…¼ë¬¸ì— ì˜í•˜ë©´,\n",
    "ì´ ê³„ì¸µì´ ê²½ì‚¬í•˜ê°•ë²•(gradient-descent)ì˜ íë¦„ì— ì¤‘ìš”í•œ ì˜í–¥ì„ ë¯¸ì¹˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œë ¤ì ¸ ìˆìŠµë‹ˆë‹¤.\n",
    "ì•„ë˜ì˜ ê·¸ë¦¼ì€ DCGAN ë…¼ë¬¸ì—ì„œ ê°€ì ¸ì˜¨ ìƒì„±ìì˜ ëª¨ë¸ ì•„í‚¤í…ì³ì…ë‹ˆë‹¤.\n",
    "\n",
    ".. figure:: /_static/img/dcgan_generator.png\n",
    "   :alt: dcgan_generator\n",
    "\n",
    "ìš°ë¦¬ê°€ ì„¤ì •ê°’ ì„¹ì…˜ì—ì„œ ì •ì˜í•œ ê°’ë“¤ì´ (``nz``, ``ngf``, ê·¸ë¦¬ê³ \n",
    "``nc``) ìƒì„±ì ëª¨ë¸ ì•„í‚¤í…ì³ì— ì–´ë–»ê²Œ ì˜í–¥ì„ ë¼ì¹˜ëŠ”ì§€ ì£¼ëª©í•´ì£¼ì„¸ìš”. ``nz`` ëŠ” z ì…ë ¥ ë²¡í„°ì˜\n",
    "ê¸¸ì´, ``ngf`` ëŠ” ìƒì„±ìë¥¼ í†µê³¼í•˜ëŠ” íŠ¹ì§• ë°ì´í„°ì˜ í¬ê¸°, ê·¸ë¦¬ê³  ``nc`` ëŠ” ì¶œë ¥ ì´ë¯¸ì§€ì˜\n",
    "ì±„ë„ ê°œìˆ˜ì…ë‹ˆë‹¤ (RGB ì´ë¯¸ì§€ì´ê¸° ë•Œë¬¸ì— 3ìœ¼ë¡œ ì„¤ì •ì„ í–ˆìŠµë‹ˆë‹¤).\n",
    "ì•„ë˜ëŠ” ìƒì„±ìì˜ ì½”ë“œì…ë‹ˆë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ì ì½”ë“œ\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # ì…ë ¥ë°ì´í„° Zê°€ ê°€ì¥ ì²˜ìŒ í†µê³¼í•˜ëŠ” ì „ì¹˜ í•©ì„±ê³± ê³„ì¸µì…ë‹ˆë‹¤.\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(nc) x 64 x 64``\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì¢‹ìŠµë‹ˆë‹¤. ì´ì œ ìš°ë¦¬ëŠ” ìƒì„±ìì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“¤ê³  ``weights_init``\n",
    "í•¨ìˆ˜ë¥¼ ì ìš©ì‹œí‚¬ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëª¨ë¸ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¶œë ¥í•´ì„œ ìƒì„±ìê°€\n",
    "ì–´ë–»ê²Œ êµ¬ì„±ë˜ì–´ìˆëŠ”ì§€ í™•ì¸í•´ë´…ì‹œë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ìƒì„±ìë¥¼ ë§Œë“­ë‹ˆë‹¤\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# í•„ìš”í•œ ê²½ìš° multi-GPUë¥¼ ì„¤ì • í•´ì£¼ì„¸ìš”\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# ëª¨ë“  ê°€ì¤‘ì¹˜ì˜ í‰ê· ì„ 0( ``mean=0`` ), ë¶„ì‚°ì„ 0.02( ``stdev=0.02`` )ë¡œ ì´ˆê¸°í™”í•˜ê¸° ìœ„í•´\n",
    "# ``weight_init`` í•¨ìˆ˜ë¥¼ ì ìš©ì‹œí‚µë‹ˆë‹¤\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### êµ¬ë¶„ì\n",
    "\n",
    "ì•ì„œ ì–¸ê¸‰í–ˆë“¯, êµ¬ë¶„ì $D$ ëŠ” ì…ë ¥ ì´ë¯¸ì§€ê°€ ì§„ì§œ ì´ë¯¸ì§€ì¸ì§€ (í˜¹ì€ ë°˜ëŒ€ë¡œ ê°€ì§œ ì´ë¯¸ì§€ì¸ì§€)\n",
    "íŒë³„í•˜ëŠ” ì „í†µì ì¸ ì´ì§„ ë¶„ë¥˜ ì‹ ê²½ë§ìœ¼ë¡œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë•Œ $D$ ëŠ”\n",
    "3x64x64 ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„, Conv2d, BatchNorm2d, ê·¸ë¦¬ê³  LeakyReLU ê³„ì¸µì„ í†µê³¼ì‹œì¼œ\n",
    "ë°ì´í„°ë¥¼ ê°€ê³µì‹œí‚¤ê³ , ë§ˆì§€ë§‰ ì¶œë ¥ì—ì„œ Sigmoid í•¨ìˆ˜ë¥¼ ì´ìš©í•˜ì—¬\n",
    "0~1 ì‚¬ì´ì˜ í™•ë¥ ê°’ìœ¼ë¡œ ì¡°ì •í•©ë‹ˆë‹¤. ì´ ì•„í‚¤í…ì³ëŠ” í•„ìš”í•œ ê²½ìš° ë” ë‹¤ì–‘í•œ ë ˆì´ì–´ë¥¼ ìŒ“ì„ ìˆ˜ ìˆì§€ë§Œ,\n",
    "ë°°ì¹˜ ì •ê·œí™”ì™€ LeakyReLU, íŠ¹íˆ ë³´í­ì´ ìˆëŠ” (strided) í•©ì„±ê³± ê³„ì¸µì„\n",
    "ì‚¬ìš©í•˜ëŠ” ê²ƒì—ëŠ” ì´ìœ ê°€ ìˆìŠµë‹ˆë‹¤.\n",
    "DCGAN ë…¼ë¬¸ì—ì„œëŠ” ë³´í­ì´ ìˆëŠ” í•©ì„±ê³± ê³„ì¸µì„ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì‹ ê²½ë§ ë‚´ì—ì„œ ìŠ¤ìŠ¤ë¡œì˜\n",
    "í’€ë§(Pooling) í•¨ìˆ˜ë¥¼ í•™ìŠµí•˜ê¸° ë•Œë¬¸ì—, ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” ê³¼ì •ì—ì„œ ì§ì ‘ì ìœ¼ë¡œ í’€ë§ ê³„ì¸µ( MaxPool or AvgPooling)ì„\n",
    "ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” ìœ ë¦¬í•˜ë‹¤ê³  í•©ë‹ˆë‹¤. ë˜í•œ ë°°ì¹˜ ì •ê·œí™”ì™€ leaky relu í•¨ìˆ˜ëŠ” í•™ìŠµê³¼ì •ì—ì„œ\n",
    "$G$ ì™€ $D$ ê°€ ë” íš¨ê³¼ì ì¸ ê²½ì‚¬ë„(gradient)ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ë¶„ì ì½”ë“œ\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # ì…ë ¥ ë°ì´í„°ì˜ í¬ê¸°ëŠ” ``(nc) x 64 x 64`` ì…ë‹ˆë‹¤\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(ndf) x 32 x 32``\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(ndf*2) x 16 x 16``\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(ndf*4) x 8 x 8``\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # ìœ„ì˜ ê³„ì¸µì„ í†µê³¼í•œ ë°ì´í„°ì˜ í¬ê¸°. ``(ndf*8) x 4 x 4``\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ì´ì œ ìš°ë¦¬ëŠ” ìƒì„±ìì— í•œ ê²ƒì²˜ëŸ¼ êµ¬ë¶„ìì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë§Œë“¤ê³ ,\n",
    "``weights_init`` í•¨ìˆ˜ë¥¼ ì ìš©ì‹œí‚¨ ë‹¤ìŒ, ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì¶œë ¥í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# êµ¬ë¶„ìë¥¼ ë§Œë“­ë‹ˆë‹¤\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# í•„ìš”í•œ ê²½ìš° multi-GPUë¥¼ ì„¤ì • í•´ì£¼ì„¸ìš”\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# ëª¨ë“  ê°€ì¤‘ì¹˜ì˜ í‰ê· ì„ 0( ``mean=0`` ), ë¶„ì‚°ì„ 0.02( ``stdev=0.02`` )ë¡œ ì´ˆê¸°í™”í•˜ê¸° ìœ„í•´\n",
    "# ``weight_init`` í•¨ìˆ˜ë¥¼ ì ìš©ì‹œí‚µë‹ˆë‹¤\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# ëª¨ë¸ì˜ êµ¬ì¡°ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ì†ì‹¤í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n",
    "\n",
    "$D$ ì™€ $G$ ì˜ ì„¤ì •ì„ ëëƒˆìœ¼ë‹ˆ, ì´ì œ ì†ì‹¤í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì •í•˜ì—¬\n",
    "í•™ìŠµì„ êµ¬ì²´í™”ì‹œí‚¬ ì‹œê°„ì…ë‹ˆë‹¤. ì†ì‹¤í•¨ìˆ˜ë¡œëŠ” Binary Cross Entropy loss\n",
    "([BCELoss](https://pytorch.org/docs/stable/generated/torch.nn.BCELoss.html#torch.nn.BCELoss)_)\n",
    "ë¥¼ ì‚¬ìš©í• ê²ë‹ˆë‹¤. í•´ë‹¹í•¨ìˆ˜ëŠ” ì•„ë˜ì˜ ì‹ìœ¼ë¡œ íŒŒì´í† ì¹˜ì— êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤:\n",
    "\n",
    "\\begin{align}\\ell(x, y) = L = \\{l_1,\\dots,l_N\\}^\\top, \\quad l_n = - \\left[ y_n \\cdot \\log x_n + (1 - y_n) \\cdot \\log (1 - x_n) \\right]\\end{align}\n",
    "\n",
    "ì´ë•Œ, ìœ„ì˜ í•¨ìˆ˜ê°€ ë¡œê·¸í•¨ìˆ˜ ìš”ì†Œë¥¼ ì •ì˜í•œ ë°©ì‹ì„ ì£¼ì˜ê¹Šê²Œ ë´ì£¼ì„¸ìš” (ì˜ˆ. $log(D(x))$ ì™€\n",
    "$log(1-D(G(z)))$). ìš°ë¦° $y$ ì„ ì¡°ì •ì„ ì¡°ì •í•˜ì—¬, BCE í•¨ìˆ˜ì—ì„œ\n",
    "ì‚¬ìš©í•  ìš”ì†Œë¥¼ ê³ ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "ì´ ë¶€ë¶„ì€ ì´í›„ì— ì„œìˆ í•  í•™ìŠµ ì„¹ì…˜ì—ì„œ ë‹¤ë£¨ê² ì§€ë§Œ, ì–´ë–»ê²Œ $y$ ë¥¼ ì´ìš©í•˜ì—¬\n",
    "ìš°ë¦¬ê°€ ì›í•˜ëŠ” ìš”ì†Œë“¤ë§Œ ê³¨ë¼ë‚¼ ìˆ˜ ìˆëŠ”ì§€ ì´í•´í•˜ëŠ” ê²ƒì´ ë¨¼ì €ì…ë‹ˆë‹¤ (ì˜ˆ.Â GT labels).\n",
    "\n",
    "ì¢‹ìŠµë‹ˆë‹¤. ë‹¤ìŒìœ¼ë¡œ ë„˜ì–´ê°€ê² ìŠµë‹ˆë‹¤. ì°¸ ë¼ë²¨ (í˜¹ì€ ì •ë‹µ)ì€ 1ë¡œ ë‘ê³ , ê±°ì§“ ë¼ë²¨ (í˜¹ì€ ì˜¤ë‹µ)ì€ 0ìœ¼ë¡œ\n",
    "ë‘ê² ìŠµë‹ˆë‹¤. ê° ë¼ë²¨ì˜ ê°’ì„ ì •í•œê±´ GAN ë…¼ë¬¸ì—ì„œ ì‚¬ìš©ëœ ê°’ë“¤ë¡œ, GANì„ êµ¬ì„±í• ë•Œì˜ ê´€ë¡€ë¼ í• \n",
    "ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë°©ê¸ˆ ì •í•œ ë¼ë²¨ ê°’ë“¤ì€ ì¶”í›„ì— ì†ì‹¤ê°’ì„ ê³„ì‚°í•˜ëŠ” ê³¼ì •ì—ì„œ ì‚¬ìš©ë ê²ë‹ˆë‹¤.\n",
    "ë§ˆì§€ë§‰ìœ¼ë¡œ, ì„œë¡œ êµ¬ë¶„ë˜ëŠ” ë‘ ì˜µí‹°ë§ˆì´ì €ë¥¼ êµ¬ì„±í•˜ê² ìŠµë‹ˆë‹¤. í•˜ë‚˜ëŠ” $D$ ë¥¼ ìœ„í•œ ê²ƒ,\n",
    "ë‹¤ë¥¸ í•˜ë‚˜ëŠ” $G$ ë¥¼ ìœ„í•œ ê²ƒì…ë‹ˆë‹¤. DCGANì— ì„œìˆ ëœ ëŒ€ë¡œ, ë‘ ì˜µí‹°ë§ˆì´ì €ëŠ” ëª¨ë‘ Adamì„ ì‚¬ìš©í•˜ê³ ,\n",
    "í•™ìŠµë¥ ì€ 0.0002, Beta1 ê°’ì€ 0.5ë¡œ ë‘¡ë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ, í•™ìŠµì´ ì§„í–‰ë˜ëŠ” ë™ì•ˆ ìƒì„±ìì˜ ìƒíƒœë¥¼ ì•Œì•„ë³´ê¸° ìœ„í•˜ì—¬,\n",
    "í”„ë¡œê·¸ë¨ì´ ëë‚ ë•Œê¹Œì§€ ê³ ì •ëœ ì ì¬ê³µê°„ ë²¡í„°ë¥¼ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤ (ì˜ˆ. fixed_noise).\n",
    "ì´ ë²¡í„°ë“¤ ì—­ì‹œ ê°€ìš°ì‹œì•ˆ ë¶„í¬ì—ì„œ ì¶”ì¶œí•©ë‹ˆë‹¤. í•™ìŠµ ê³¼ì •ì„ ë°˜ë³µí•˜ë©´ì„œ  $G$ ì— ì£¼ê¸°ì ìœ¼ë¡œ ê°™ì€ ì ì¬ê³µê°„ ë²¡í„°ë¥¼\n",
    "ì…ë ¥í•˜ë©´, ê·¸ ì¶œë ¥ê°’ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±ìì˜ ìƒíƒœë¥¼ í™•ì¸ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ``BCELoss`` í•¨ìˆ˜ì˜ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# ìƒì„±ìì˜ í•™ìŠµìƒíƒœë¥¼ í™•ì¸í•  ì ì¬ ê³µê°„ ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "\n",
    "# í•™ìŠµì— ì‚¬ìš©ë˜ëŠ” ì°¸/ê±°ì§“ì˜ ë¼ë²¨ì„ ì •í•©ë‹ˆë‹¤\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Gì™€ Dì—ì„œ ì‚¬ìš©í•  Adamì˜µí‹°ë§ˆì´ì €ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### í•™ìŠµ\n",
    "\n",
    "ë“œë””ì–´ ìµœì¢…ì…ë‹ˆë‹¤. GAN í”„ë ˆì„ì›Œí¬ì— í•„ìš”í•œ ë¶€ë¶„ë“¤ì€ ëª¨ë‘ ê°€ì¡Œìœ¼ë‹ˆ,\n",
    "ì‹¤ì œ ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” ë°©ë²•ì„ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤. ì£¼ì˜ë¥¼ ê¸°ìš¸ì¼ ê²ƒì€, GANì„ í•™ìŠµì‹œí‚¤ëŠ” ê±´\n",
    "ê´€ë¡€ì ì¸ ê¸°ìˆ ë“¤ì˜ ì§‘í•©ì´ê¸° ë•Œë¬¸ì—, ì˜ëª»ëœ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì˜ ì„¤ì •ì€\n",
    "ëª¨ë¸ì˜ í•™ìŠµì„ ë§ê°€ëœ¨ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë¬´ì—‡ì´ ì˜ëª»ë˜ì—ˆëŠ”ì§€ ì•Œì•„ë‚´ëŠ” ê²ƒ ì¡°ì°¨ë„ í˜ë“¤ì£ .\n",
    "ê·¸ëŸ¬í•œ ì´ìœ ë¡œ, ë³¸ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” [Goodfellowâ€™s paper](https://papers.nips.cc/paper/5423-generative-adversarial-nets.pdf)_\n",
    "ì—ì„œ ì„œìˆ ëœ Algorithm 1ì„ ê¸°ë°˜ìœ¼ë¡œ, [ganhacks](https://github.com/soumith/ganhacks)_ ì—ì„œ ì‚¬ìš©ëœ ëª‡ê°€ì§€ ê´œì°®ì€ í…Œí¬ë‹‰ë“¤ì„\n",
    "ë”í•  ê²ƒì…ë‹ˆë‹¤. ì•ì„œ ëª‡ë²ˆ ì„¤ëª…í–ˆì§€ë§Œ, ìš°ë¦¬ì˜ ì˜ë„ëŠ” â€œì§„ì§œ í˜¹ì€ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ êµ¬ì„±â€í•˜ê³ ,\n",
    "$log(D(G(z)))$ ë¥¼ ìµœëŒ€í™”í•˜ëŠ” Gì˜ ëª©ì í•¨ìˆ˜ë¥¼ ìµœì í™” ì‹œí‚¤ëŠ” ê²ë‹ˆë‹¤. í•™ìŠµê³¼ì •ì€ í¬ê²Œ ë‘ê°€ì§€ë¡œ ë‚˜ëˆ•ë‹ˆë‹¤.\n",
    "Part 1ì€ êµ¬ë¶„ìë¥¼, Part 2ëŠ” ìƒì„±ìë¥¼ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.\n",
    "\n",
    "**Part 1 - êµ¬ë¶„ìì˜ í•™ìŠµ**\n",
    "\n",
    "êµ¬ë¶„ìì˜ ëª©ì ì€ ì£¼ì–´ì§„ ì…ë ¥ê°’ì´ ì§„ì§œì¸ì§€ ê°€ì§œì¸ì§€ íŒë³„í•˜ëŠ” ê²ƒì„ì„ ìƒê¸°í•©ì‹œë‹¤.\n",
    "Goodfellowì˜ ë§ì„ ë¹Œë¦¬ìë©´, êµ¬ë¶„ìëŠ” â€œë³€í™”ë„(gradient)ë¥¼ ìƒìŠ¹(ascending)ì‹œí‚¤ë©° í›ˆë ¨â€í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "ì‹¤ì „ì ìœ¼ë¡œ ì–˜ê¸°í•˜ë©´, $log(D(x)) + log(1-D(G(z)))$ ë¥¼ ìµœëŒ€í™”ì‹œí‚¤ëŠ” ê²ƒê³¼ ê°™ìŠµë‹ˆë‹¤.\n",
    "[ganhacks](https://github.com/soumith/ganhacks)_ ì—ì„œ ë¯¸ë‹ˆ ë°°ì¹˜(mini-batch)ë¥¼ ë¶„ë¦¬í•˜ì—¬ ì‚¬ìš©í•œ ê°œë…ì„ ê°€ì ¸ì™€ì„œ,\n",
    "ìš°ë¦¬ ì—­ì‹œ ë‘ê°€ì§€ ìŠ¤í…ìœ¼ë¡œ ë¶„ë¦¬í•´ ê³„ì‚°ì„ í•´ë³´ê² ìŠµë‹ˆë‹¤. ë¨¼ì €,\n",
    "ì§„ì§œ ë°ì´í„°ë“¤ë¡œë§Œ ì´ë£¨ì–´ì§„ ë°°ì¹˜ë¥¼ ë§Œë“¤ì–´ $D$ ì— í†µê³¼ì‹œí‚µë‹ˆë‹¤. ê·¸ ì¶œë ¥ê°’ìœ¼ë¡œ ($log(D(x))$) ì˜ ì†ì‹¤ê°’ì„ ê³„ì‚°í•˜ê³ ,\n",
    "ì—­ì „íŒŒ ê³¼ì •ì—ì„œì˜ ë³€í™”ë„ë“¤ì„ ê³„ì‚°í•©ë‹ˆë‹¤. ì—¬ê¸°ê¹Œì§€ê°€ ì²«ë²ˆì§¸ ìŠ¤í…ì…ë‹ˆë‹¤. ë‘ë²ˆì§¸ ìŠ¤í…ì—ì„œëŠ”, ì˜¤ë¡œì§€ ê°€ì§œ ë°ì´í„°ë“¤ë¡œë§Œ\n",
    "ì´ë£¨ì–´ì§„ ë°°ì¹˜ë¥¼ ë§Œë“¤ì–´ $D$ ì— í†µê³¼ì‹œí‚¤ê³ , ê·¸ ì¶œë ¥ê°’ìœ¼ë¡œ ($log(1-D(G(z)))$) ì˜ ì†ì‹¤ê°’ì„ ê³„ì‚°í•´\n",
    "ì—­ì „íŒŒ ë³€í™”ë„ë¥¼ êµ¬í•˜ë©´ ë©ë‹ˆë‹¤. ì´ë•Œ ë‘ê°€ì§€ ìŠ¤í…ì—ì„œ ë‚˜ì˜¤ëŠ” ë³€í™”ë„ë“¤ì€ *ì¶•ì (accumulate)* ì‹œì¼œì•¼ í•©ë‹ˆë‹¤.\n",
    "ë³€í™”ë„ê¹Œì§€ êµ¬í–ˆìœ¼ë‹ˆ, ì´ì œ ì˜µí‹°ë§ˆì´ì €ë¥¼ ì‚¬ìš©í•´ì•¼ê² ì£ . íŒŒì´í† ì¹˜ì˜ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•´ì£¼ë©´ ì•Œì•„ì„œ ë³€í™”ë„ê°€ ì ìš©ë ê²ë‹ˆë‹¤.\n",
    "\n",
    "**Part 2 - ìƒì„±ìì˜ í•™ìŠµ**\n",
    "\n",
    "ì˜¤ë¦¬ì§€ë„ GAN ë…¼ë¬¸ì— ëª…ì‹œë˜ì–´ ìˆë“¯, ìƒì„±ìëŠ” $log(1-D(G(z)))$ ì„ ìµœì†Œí™”ì‹œí‚¤ëŠ” ë°©í–¥ìœ¼ë¡œ í•™ìŠµí•©ë‹ˆë‹¤.\n",
    "í•˜ì§€ë§Œ ì´ ë°©ì‹ì€ ì¶©ë¶„í•œ ë³€í™”ë„ë¥¼ ì œê³µí•˜ì§€ ëª»í•¨ì„ Goodfellowê°€ ë³´ì—¬ì¤¬ìŠµë‹ˆë‹¤. íŠ¹íˆ í•™ìŠµì´ˆê¸°ì—ëŠ” ë”ìš± ë¬¸ì œë¥¼ ì¼ìœ¼í‚¤ì£ .\n",
    "ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ $log(D(G(z)))$ ë¥¼ ìµœëŒ€í™” í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë°”ê¿”ì„œ í•™ìŠµì„ í•˜ê² ìŠµë‹ˆë‹¤. ì½”ë“œì—ì„œ êµ¬í˜„í•˜ê¸°\n",
    "ìœ„í•´ì„œëŠ” : Part 1ì—ì„œ í•œëŒ€ë¡œ êµ¬ë¶„ìë¥¼ ì´ìš©í•´ ìƒì„±ìì˜ ì¶œë ¥ê°’ì„ íŒë³„í•´ì£¼ê³ , *ì§„ì§œ ë¼ë²¨ê°’* ì„ ì´ìš©í•´ Gì˜ ì†ì‹¤ê°’ì„ êµ¬í•´ì¤ë‹ˆë‹¤.\n",
    "ê·¸ëŸ¬ë©´ êµ¬í•´ì§„ ì†ì‹¤ê°’ìœ¼ë¡œ ë³€í™”ë„ë¥¼ êµ¬í•˜ê³ , ìµœì¢…ì ìœ¼ë¡œëŠ” ì˜µí‹°ë§ˆì´ì €ë¥¼ ì´ìš©í•´ Gì˜ ê°€ì¤‘ì¹˜ë“¤ì„ ì—…ë°ì´íŠ¸ì‹œì¼œì£¼ë©´ ë©ë‹ˆë‹¤.\n",
    "ì–¸ëœ» ë³¼ë•ŒëŠ”, ìƒì„±ìê°€ ë§Œë“¤ì–´ë‚¸ *ê°€ì§œ* ì´ë¯¸ì§€ì— *ì§„ì§œ* ë¼ë²¨ì„ ì‚¬ìš©í•˜ëŠ”ê²ƒì´ ì§ê´€ì ìœ¼ë¡œ ìœ„ë°°ê°€ ë í…Œì§€ë§Œ, ì´ë ‡ê²Œ ë¼ë²¨ì„\n",
    "ë°”ê¿ˆìœ¼ë¡œì¨ $log(x)$ ë¼ëŠ” ``BCELoss`` ì˜ ì¼ë¶€ë¶„ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤ (ì•ì„œ ìš°ë¦¬ëŠ” BCELossì—ì„œ ë¼ë²¨ì„ ì´ìš©í•´ ì›í•˜ëŠ” ë¡œê·¸ ê³„ì‚°\n",
    "ìš”ì†Œë¥¼ ê³ ë¥¼ ìˆ˜ ìˆìŒì„ ì•Œì•„ë´¤ìŠµë‹ˆë‹¤).\n",
    "\n",
    "ë§ˆë¬´ë¦¬ë¡œ Gì˜ í›ˆë ¨ ìƒíƒœë¥¼ ì•Œì•„ë³´ê¸° ìœ„í•˜ì—¬, ëª‡ê°€ì§€ í†µê³„ì ì¸ ìˆ˜ì¹˜ë“¤ê³¼, fixed_noiseë¥¼ í†µê³¼ì‹œí‚¨\n",
    "ê²°ê³¼ë¥¼ í™”ë©´ì— ì¶œë ¥í•˜ëŠ” ì½”ë“œë¥¼ ì¶”ê°€í•˜ê² ìŠµë‹ˆë‹¤. ì´ë•Œ í†µê³„ì ì¸ ìˆ˜ì¹˜ë“¤ì´ë¼ í•¨ì€:\n",
    "\n",
    "-  **Loss_D** - ì§„ì§œ ë°ì´í„°ì™€ ê°€ì§œ ë°ì´í„°ë“¤ ëª¨ë‘ì—ì„œ êµ¬í•´ì§„ ì†ì‹¤ê°’. ($log(D(x)) + log(1 - D(G(z)))$).\n",
    "-  **Loss_G** - ìƒì„±ìì˜ ì†ì‹¤ê°’. $log(D(G(z)))$\n",
    "-  **D(x)** - êµ¬ë¶„ìê°€ ë°ì´í„°ë¥¼ íŒë³„í•œ í™•ë¥ ê°’ì…ë‹ˆë‹¤. ì²˜ìŒì—ëŠ” 1ì— ê°€ê¹Œìš´ ê°’ì´ë‹¤ê°€,\n",
    "   Gê°€ í•™ìŠµí• ìˆ˜ë¡ 0.5ê°’ì— ìˆ˜ë ´í•˜ê²Œ ë©ë‹ˆë‹¤.\n",
    "-  **D(G(z))** - ê°€ì§œë°ì´í„°ë“¤ì— ëŒ€í•œ êµ¬ë¶„ìì˜ ì¶œë ¥ê°’ì…ë‹ˆë‹¤. ì²˜ìŒì—ëŠ” 0ì— ê°€ê¹Œìš´ ê°’ì´ë‹¤ê°€,\n",
    "   Gê°€ í•™ìŠµí• ìˆ˜ë¡ 0.5ì— ìˆ˜ë ´í•˜ê²Œ ë©ë‹ˆë‹¤\n",
    "\n",
    "\n",
    "**Note:** ì´í›„ì˜ ê³¼ì •ì€ epochì˜ ìˆ˜ì™€ ë°ì´í„°ì˜ ìˆ˜ì— ë”°ë¼ ì‹œê°„ì´ ì¢€ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•™ìŠµ ê³¼ì •\n",
    "\n",
    "# í•™ìŠµìƒíƒœë¥¼ ì²´í¬í•˜ê¸° ìœ„í•´ ì†ì‹¤ê°’ë“¤ì„ ì €ì¥í•©ë‹ˆë‹¤\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# ì—í­(epoch) ë°˜ë³µ\n",
    "for epoch in range(num_epochs):\n",
    "    # í•œ ì—í­ ë‚´ì—ì„œ ë°°ì¹˜ ë°˜ë³µ\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # (1) D ì‹ ê²½ë§ì„ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤\n",
    "        # log(D(x)) + log(1 - D(G(z)))ë¥¼ ìµœëŒ€í™” í•©ë‹ˆë‹¤\n",
    "        ###########################\n",
    "        ## ì§„ì§œ ë°ì´í„°ë“¤ë¡œ í•™ìŠµì„ í•©ë‹ˆë‹¤\n",
    "        netD.zero_grad()\n",
    "        # ë°°ì¹˜ë“¤ì˜ ì‚¬ì´ì¦ˆë‚˜ ì‚¬ìš©í•  ë””ë°”ì´ìŠ¤ì— ë§ê²Œ ì¡°ì •í•©ë‹ˆë‹¤\n",
    "        real_cpu = data[0].to(device)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label,\n",
    "                        dtype=torch.float, device=device)\n",
    "        # ì§„ì§œ ë°ì´í„°ë“¤ë¡œ ì´ë£¨ì–´ì§„ ë°°ì¹˜ë¥¼ Dì— í†µê³¼ì‹œí‚µë‹ˆë‹¤\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # ì†ì‹¤ê°’ì„ êµ¬í•©ë‹ˆë‹¤\n",
    "        errD_real = criterion(output, label)\n",
    "        # ì—­ì „íŒŒì˜ ê³¼ì •ì—ì„œ ë³€í™”ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## ê°€ì§œ ë°ì´í„°ë“¤ë¡œ í•™ìŠµì„ í•©ë‹ˆë‹¤\n",
    "        # ìƒì„±ìì— ì‚¬ìš©í•  ì ì¬ê³µê°„ ë²¡í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # Gë¥¼ ì´ìš©í•´ ê°€ì§œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # Dë¥¼ ì´ìš©í•´ ë°ì´í„°ì˜ ì§„ìœ„ë¥¼ íŒë³„í•©ë‹ˆë‹¤\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # Dì˜ ì†ì‹¤ê°’ì„ ê³„ì‚°í•©ë‹ˆë‹¤\n",
    "        errD_fake = criterion(output, label)\n",
    "        # ì—­ì „íŒŒë¥¼ í†µí•´ ë³€í™”ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.\n",
    "        # ì´ë•Œ ì•ì„œ êµ¬í•œ ë³€í™”ë„ì— ë”í•©ë‹ˆë‹¤(accumulate)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # ê°€ì§œ ì´ë¯¸ì§€ì™€ ì§„ì§œ ì´ë¯¸ì§€ ëª¨ë‘ì—ì„œ êµ¬í•œ ì†ì‹¤ê°’ë“¤ì„ ë”í•©ë‹ˆë‹¤\n",
    "        # ì´ë•Œ errDëŠ” ì—­ì „íŒŒì—ì„œ ì‚¬ìš©ë˜ì§€ ì•Šê³ ,\n",
    "        # ì´í›„ í•™ìŠµ ìƒíƒœë¥¼ ë¦¬í¬íŒ…(reporting)í•  ë•Œ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
    "        errD = errD_real + errD_fake\n",
    "        # Dë¥¼ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) G ì‹ ê²½ë§ì„ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤: log(D(G(z)))ë¥¼ ìµœëŒ€í™” í•©ë‹ˆë‹¤\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)\n",
    "        # ìƒì„±ìì˜ ì†ì‹¤ê°’ì„ êµ¬í•˜ê¸° ìœ„í•´ ì§„ì§œ ë¼ë²¨ì„ ì´ìš©\n",
    "\n",
    "        # ìš°ë¦¬ëŠ” ë°©ê¸ˆ Dë¥¼ ì—…ë°ì´íŠ¸í–ˆê¸° ë•Œë¬¸ì—,\n",
    "        # Dì— ë‹¤ì‹œ ê°€ì§œ ë°ì´í„°ë¥¼ í†µê³¼ì‹œí‚µë‹ˆë‹¤.\n",
    "\n",
    "        # ì´ë•Œ GëŠ” ì—…ë°ì´íŠ¸ë˜ì§€ ì•Šì•˜ì§€ë§Œ,\n",
    "        # Dê°€ ì—…ë°ì´íŠ¸ ë˜ì—ˆê¸° ë•Œë¬¸ì— ì•ì„  ì†ì‹¤ê°’ê°€ ë‹¤ë¥¸ ê°’ì´ ë‚˜ì˜¤ê²Œ ë©ë‹ˆë‹¤\n",
    "        output = netD(fake).view(-1)\n",
    "        # Gì˜ ì†ì‹¤ê°’ì„ êµ¬í•©ë‹ˆë‹¤\n",
    "        errG = criterion(output, label)\n",
    "        # Gì˜ ë³€í™”ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # Gë¥¼ ì—…ë°ì´íŠ¸ í•©ë‹ˆë‹¤\n",
    "        optimizerG.step()\n",
    "\n",
    "        # í›ˆë ¨ ìƒíƒœë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                % (epoch, num_epochs, i, len(dataloader),\n",
    "                    errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # ì´í›„ ê·¸ë˜í”„ë¥¼ ê·¸ë¦¬ê¸° ìœ„í•´ ì†ì‹¤ê°’ë“¤ì„ ì €ì¥í•´ë‘¡ë‹ˆë‹¤\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # fixed_noiseë¥¼ í†µê³¼ì‹œí‚¨ Gì˜ ì¶œë ¥ê°’ì„ ì €ì¥í•´ë‘¡ë‹ˆë‹¤\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ê²°ê³¼\n",
    "\n",
    "ê²°ê³¼ë¥¼ ì•Œì•„ë´…ì‹œë‹¤. ì´ ì„¹ì…˜ì—ì„œëŠ” ì´ ì„¸ê°€ì§€ë¥¼ í™•ì¸í• ê²ë‹ˆë‹¤.\n",
    "\n",
    "ì²«ë²ˆì§¸ëŠ” Gì™€ Dì˜ ì†ì‹¤ê°’ë“¤ì´ ì–´ë–»ê²Œ ë³€í–ˆëŠ”ê°€, ë‘ë²ˆì§¸ëŠ” ë§¤ ì—í­ë§ˆë‹¤\n",
    "fixed_noiseë¥¼ ì´ìš©í•´ Gê°€ ë§Œë“¤ì–´ë‚¸ ì´ë¯¸ì§€ë“¤, ë§ˆì§€ë§‰ì€ í•™ìŠµì´ ëë‚œ Gê°€ ë§Œë“¤ì–´ë‚¸ ì´ë¯¸ì§€ì™€\n",
    "ì§„ì§œ ì´ë¯¸ì§€ë“¤ì˜ ë¹„êµì…ë‹ˆë‹¤\n",
    "\n",
    "**í•™ìŠµí•˜ëŠ” ë™ì•ˆì˜ ì†ì‹¤ê°’ë“¤**\n",
    "\n",
    "ì•„ë˜ëŠ” Dì™€ Gì˜ ì†ì‹¤ê°’ë“¤ì„ ê·¸ë˜í”„ë¡œ ê·¸ë¦° ëª¨ìŠµì…ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gì˜ í•™ìŠµ ê³¼ì • ì‹œê°í™”**\n",
    "\n",
    "ë§¤ ì—í­ë§ˆë‹¤ fixed_noiseë¥¼ ì´ìš©í•´ ìƒì„±ìê°€ ë§Œë“¤ì–´ë‚¸ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•œ ê²ƒì„ ê¸°ì–µí• ê²ë‹ˆë‹¤.\n",
    "\n",
    "ì €ì¥í•œ ì´ë¯¸ì§€ë“¤ì„ì• ë‹ˆë©”ì´ì…˜ í˜•ì‹ìœ¼ë¡œ í™•ì¸í•´ ë´…ì‹œë‹¤. playë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì• ë‹ˆë§¤ì´ì…˜ì´ ì‹¤í–‰ë©ë‹ˆë‹¤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ì§„ì§œ ì´ë¯¸ì§€ vs.Â ê°€ì§œ ì´ë¯¸ì§€**\n",
    "\n",
    "ì§„ì§œ ì´ë¯¸ì§€ë“¤ê³¼ ê°€ì§œ ì´ë¯¸ì§€ë“¤ì„ ì˜†ìœ¼ë¡œ ë‘ê³  ë¹„êµë¥¼ í•´ë´…ì‹œë‹¤\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloaderì—ì„œ ì§„ì§œ ë°ì´í„°ë“¤ì„ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "real_batch = next(iter(dataloader))\n",
    "\n",
    "# ì§„ì§œ ì´ë¯¸ì§€ë“¤ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# ê°€ì§œ ì´ë¯¸ì§€ë“¤ì„ í™”ë©´ì— ì¶œë ¥í•©ë‹ˆë‹¤\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ì´ì œ ì–´ë””ë¡œ ì—¬í–‰ì„ ë– ë‚˜ë³¼ê¹Œìš”?\n",
    "\n",
    "ë“œë””ì–´ DCGANì´ ëë‚¬ìŠµë‹ˆë‹¤! í•˜ì§€ë§Œ ë” ì•Œì•„ë³¼ ê²ƒë“¤ì´ ë§ì´ ë‚¨ì•„ìˆì£ .\n",
    "ë¬´ì—‡ì„ ë” ì‹œë„í•´ë³¼ ìˆ˜ ìˆì„ê¹Œìš”?\n",
    "\n",
    "-  ê²°ê³¼ë¬¼ì´ ì–¼ë§ˆë‚˜ ë” ì¢‹ì•„ì§€ëŠ”ì§€ í™•ì¸í•´ë³´ê¸° ìœ„í•´ì„œ í•™ìŠµì‹œê°„ì„ ëŠ˜ë ¤ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "-  ë‹¤ë¥¸ ë°ì´í„°ì…‹ì„ ì´ìš©í•´ í›ˆë ¨ì‹œì¼œë³´ê±°ë‚˜, ì´ë¯¸ì§€ì˜ ì‚¬ì´ì¦ˆë¥¼ ë‹¤ë¥´ê²Œ í•´ë³´ê±°ë‚˜, ì•„í‚¤í…ì³ì˜ êµ¬ì„±ì„ ë°”ê¿”ë³¼ ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤\n",
    "-  [ì—¬ê¸°](https://github.com/nashory/gans-awesome-applications)_ ì—ì„œ ë”ìš± ë©‹ì§„ GAN í”„ë¡œì íŠ¸ë“¤ì„ ì°¾ì„ìˆ˜ë„ ìˆì£ \n",
    "-  [ìŒì•…](https://www.deepmind.com/blog/wavenet-a-generative-model-for-raw-audio/)_ ì„ ì‘ê³¡í•˜ëŠ” GANë„ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ì°¸ê³ ìë£Œ` \n",
    "\n",
    "- **Large-scale CelebFaces Attributes (CelebA) Dataset** : https://mmlab.ie.cuhk.edu.hk/projects/CelebA.html\n",
    "- **íŒŒì´í† ì¹˜ DCGAN íŠœí† ë¦¬ì–¼** : https://tutorials.pytorch.kr/beginner/dcgan_faces_tutorial.html\n",
    "https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\n",
    "- **Google Colabì—ì„œ íŠœí† ë¦¬ì–¼ ì‹¤í–‰í•˜ê¸°** : https://tutorials.pytorch.kr/beginner/colab"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
