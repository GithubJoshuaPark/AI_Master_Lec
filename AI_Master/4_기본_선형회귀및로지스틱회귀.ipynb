{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f8XHHT99-Slm"
   },
   "source": [
    "### Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **선형회귀 및 로지스틱 회귀**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaV6bKLx-Sls"
   },
   "source": [
    "> ## 학습 목표\n",
    "-   선형 회귀의 기본 개념과 가설 함수를 이해하고, 파이토치를 활용하여 모델을 구현하며, 학습 데이터 적합성을 평가하고 시각화할 수 있다.\n",
    "    \n",
    "    -   선형 회귀에 사용되는 손실 함수(예: MSE)의 정의와 중요성을 이해하고, 경사하강법을 통해 손실 함수를 최소화하는 파라미터 최적화 과정을 수행할 수 있다.\n",
    "    \n",
    "    -   선형 회귀의 주요 가정(선형성, 독립성, 정규성, 등분산성)을 이해하고 이들이 모델 성능에 미치는 영향을 설명할 수 있다.\n",
    "    \n",
    "-   로지스틱 회귀의 개념을 이해하고, 이진 분류 문제에 적용하며, 파이토치로 모델을 구현하고 결과를 해석할 수 있다.\n",
    "    \n",
    "-   선형 및 로지스틱 회귀 모델의 성능 평가 지표(예: R², 정확도, 정밀도, 재현율)를 이해하고, 이를 통해 모델의 효과성을 비교할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `선형회귀 및 로지스틱 회귀의 이해`\n",
    "\n",
    "선형회귀와 로지스틱 회귀는 모두 통계학과 머신러닝에서 널리 사용되는 모델링 기법입니다. \n",
    "\n",
    "두 알고리즘은 입력 변수와 출력 변수 간의 관계를 모델링하는 방식에서 차이를 보이며, 각각 다른 유형의 문제를 해결합니다.\n",
    "\n",
    "\n",
    "### **■ 선형회귀 (Linear Regression)**\n",
    "\n",
    "**1) 개념**\n",
    "\n",
    "-   선형회귀는 **연속형 출력 변수(숫자)를 예측**하기 위한 알고리즘입니다.\n",
    "-   독립 변수(입력 변수)와 종속 변수(출력 변수) 사이의 선형 관계를 가정합니다.\n",
    "-   주어진 데이터를 기반으로 최적의 직선을 찾아내는 것이 목표입니다. \n",
    "\n",
    "**2) 주요 특징**\n",
    "\n",
    "-   **목적**: 연속적인 값을 예측 (예: 집값, 매출 등)\n",
    "-   **손실 함수**: 평균제곱오차(MSE, Mean Squared Error)를 최소화\n",
    "-   **가정**:\n",
    "    -   독립 변수와 종속 변수 사이에 선형 관계가 존재\n",
    "    -   독립 변수 간 다중공선성이 없어야 함\n",
    "    -   잔차가 정규분포를 따르고 등분산성(모든 입력 값에서 일정한 분산)을 가져야 함\n",
    "\n",
    "**3) 장점**\n",
    "\n",
    "-   간단하고 해석이 용이\n",
    "-   과적합(overfitting)을 피하기 쉬움 (특히, 적은 변수일 때)\n",
    "\n",
    "**4) 한계**\n",
    "\n",
    "-   입력 변수와 출력 변수의 관계가 선형이 아닐 경우 성능 저하\n",
    "-   이상치(outlier)에 민감\n",
    "\n",
    "\n",
    "### **■  로지스틱 회귀 (Logistic Regression)**\n",
    "\n",
    "**1) 개념**\n",
    "\n",
    "-   로지스틱 회귀는 **이진 분류 문제**를 해결하기 위한 알고리즘입니다.\n",
    "-   출력 변수는 0과 1 또는 특정 클래스(예: 양성/음성)로 분류됩니다.\n",
    "-   선형 회귀와 달리, 예측값 yyy를 0과 1 사이로 제한하기 위해 \\*\\*로지스틱 함수(시그모이드 함수)\\*\\*를 사용합니다.\n",
    "\n",
    "**2) 주요 특징**\n",
    "\n",
    "-   **목적**: 특정 클래스에 속할 확률을 예측\n",
    "-   **손실 함수**: 로그손실(Log Loss) 또는 교차 엔트로피(Cross-Entropy)를 최소화\n",
    "-   **가정**:\n",
    "    -   독립 변수와 로그 오즈(log odds) 사이에 선형 관계가 존재\n",
    "    -   입력 변수 간 다중공선성이 없어야 함\n",
    "\n",
    "**3) 장점**\n",
    "\n",
    "-   확률 값을 출력하므로 해석이 용이\n",
    "-   비교적 간단하고 계산 비용이 낮음\n",
    "-   많은 종류의 분류 문제에서 효율적으로 사용 가능\n",
    "\n",
    "**4) 한계**\n",
    "\n",
    "-   선형적으로 분리되지 않는 데이터에서는 성능이 저하\n",
    "-   다중 클래스 문제에서는 확장을 위해 OvR(One-vs-Rest)이나 소프트맥스(Softmax) 방법이 필요\n",
    "\n",
    "### **차이점 비교**\n",
    "\n",
    "| 특징 | 선형회귀 | 로지스틱 회귀 |\n",
    "| --- | --- | --- |\n",
    "| **출력 값** | 연속적인 값 (실수) | 확률 (0~1) 또는 이진 분류 (0, 1) |\n",
    "| **문제 유형** | 회귀 문제 | 분류 문제 |\n",
    "| **주요 함수** | 직선 방정식 | 시그모이드 함수 |\n",
    "| **손실 함수** | 평균제곱오차 (MSE) | 로그손실 (Log Loss) 또는 교차 엔트로피 |\n",
    "| **결과 해석** | 예측 값 자체 | 특정 클래스에 속할 확률 |\n",
    "| **한계** | 비선형 관계에서는 부적합 | 선형적으로 분리되지 않는 데이터에서 성능 저하 |\n",
    "\n",
    "### **응용 사례**\n",
    "\n",
    "-   **선형 회귀**: 주택 가격 예측, 주식 시장 분석, 날씨 예측 등\n",
    "-   **로지스틱 회귀**: 스팸 메일 분류, 질병 유무 판별, 고객 이탈 예측 등"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 선형회귀 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 선형회귀(Linear Regression)는 입력 변수(x)와 출력 변수(y) 간의 선형관계를 모델링하는 머신러닝 알고리즘입니다.\n",
    "- 선형회귀는 주어진 입력값을 기반으로 연속적인 출력값을 예측하는 간단한 형태의 회귀 분석 방법입니다. \n",
    "- 선형회귀는 일차 함수 **y = wx + b** 로 표현할 수 있습니다. (x는 독립변수, y는 종속변수, w는 가중치, b는 편향)\n",
    "- 단순선형회귀는 한 개의 독립변수와 한 개의 종속변수의 관계를 의미합니다.\n",
    "- 다중선형회귀는 독립변수가 여러 개일 경우입니다.    \n",
    "- 독립변수 x값에 따라 종속변수 y값은 달라집니다.\n",
    "- 선형회귀의 주요 목표는 모델의 가중치 w와 절편 b를 학습하여 주어진 데이터에 대하여 예측 오차를 최소화하는 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./image/4.1_선형회귀그래프.png\" width=\"600\">\n",
    "<figcaption>그림 4.1 선형회귀 그래프</figcaption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1 라이브러리 임포트"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파이토치에서는 기본적인 신경망 모델을 구축할 수 있는 도구들이 제공됩니다.\n",
    "- torch.nn은 신경망 구축에 필요한 라이브러리입니다.\n",
    "- torch.optim은 최적화 알고리즘 제공 라이브러리입니다.\n",
    "- matplotlib.pyplot은 그래프를 그릴 때 사용하는 시각화 라이브러리입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 라이브러리\n",
    "import torch\n",
    "\n",
    "# 신경망 모델 정의\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch.optim 신경망 학습을 위한 최적화 알고리즘 제공 경사하강법, Adam 등\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt  # 데이터 시각화 그래프\n",
    "import numpy as np        # 연산 처리\n",
    "\n",
    "\n",
    "# 1. 데이터 준비\n",
    "# 월별 매출 데이터 (1월~12월)\n",
    "months = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12], dtype=np.float32)\n",
    "\n",
    "# 매출 데이터 (단위: 백만 원)\n",
    "sales = np.array([2.5, 3.0, 3.2, 4.0, 4.5, 4.8, 5.0, 5.2, 5.5, 5.7, 6.0, 6.3], dtype=np.float32)\n",
    "\n",
    "# 2. 데이터를 파이토치 텐서로 변환\n",
    "months_tensor = torch.tensor(months).view(-1, 1)\n",
    "sales_tensor = torch.tensor(sales).view(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3 선형회귀 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 3. 선형회귀 모델 정의\n",
    "# nn.Module은 신경망 모델을 만들 때 상속하는 기본 클래스, 레이어, 순전파 메소드 정의\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):     # 부모 클래스인 nn.Module의 초기화 메서드를 호출\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "        # 1개의 입력과 1개의 출력을 갖는 선형 모델\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 순전파 함수. 입력 x를 선형 레이어를 통과시켜 출력값을 반환합니다.\n",
    "        return self.linear(x)\n",
    "\n",
    "# 4. 모델 초기화\n",
    "# 정의한 선형회귀 모델을 초기화합니다.\n",
    "model = LinearRegressionModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nn.Module은 PyTorch에서 신경망 모델을 정의할 때 기본적으로 상속해야 하는 클래스입니다.\n",
    "- LinearRegressionModel 클래스에서는 nn.Linear(1, 1)을 사용하여 1개의 입력과 1개의 출력을 갖는 선형 레이어를 정의합니다.\n",
    "- forward 메서드는 입력 데이터를 받아서 순전파를 통해 출력을 계산하는 함수입니다.\n",
    "- model = LinearRegressionModel()는 모델을 초기화하는 코드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.4 손실 함수와 옵티마이저 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 5. 손실 함수와 옵티마이저 설정\n",
    "criterion = nn.MSELoss()  # 선형회귀에 평균 제곱 오차 사용\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "# 확률적 경사 하강법, lr 학습률"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.5 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 6. 모델 학습\n",
    "epochs = 1000  # 학습할 에폭 수 설정\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # # 순전파: 모델을 통해 입력 데이터를 처리하여 예측값을 계산합니다.\n",
    "    outputs = model(months_tensor)\n",
    "    # 손실 함수 계산: 모델의 출력값과 실제 값(판매량) 간의 차이를 계산합니다.\n",
    "    loss = criterion(outputs, sales_tensor)\n",
    "\n",
    "    # 역전파\n",
    "    optimizer.zero_grad()  # 이전 기울기 초기화\n",
    "    loss.backward()        # 기울기 계산\n",
    "    optimizer.step()       # 가중치 업데이트\n",
    "\n",
    "    # 100 에폭마다 현재 에폭과 손실 값을 출력합니다.\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 7. 학습된 모델의 파라미터 확인\n",
    "# 학습이 완료된 후, 모델의 기울기(가중치)와 절편 값을 출력합니다.\n",
    "print(f'기울기: {model.linear.weight.item():.4f}')   # 모델의 가중치 출력\n",
    "print(f'절편: {model.linear.bias.item():.4f}')      # 모델의 절편 출력\n",
    "\n",
    "# 8. 예측값 계산\n",
    "# 학습된 모델을 사용하여 예측값을 계산합니다.\n",
    "# .detach()는 텐서를 계산 그래프에서 분리하여, NumPy로 변환할 수 있게 합니다.\n",
    "predicted_sales = model(months_tensor).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 9. 결과 시각화\n",
    "plt.scatter(months, sales, color='blue')  # 실제 매출\n",
    "plt.plot(months, predicted_sales, color='red') # 선형 회귀 예측\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "# 폰트 파일 경로 직접 지정\n",
    "# font_path = '/System/Library/Fonts/AppleSDGothicNeo.ttc'  # 맥OS에 기본 설치된 한글 폰트\n",
    "# fontprop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# plt.scatter(months, sales, color='blue', label='실제 매출')\n",
    "# plt.plot(months, predicted_sales, color='red', label='선형 회귀 예측')\n",
    "# plt.xlabel('월', fontproperties=fontprop)\n",
    "# plt.ylabel('매출 (백만 원)', fontproperties=fontprop)\n",
    "# plt.title('선형 회귀 - 월별 매출 예측', fontproperties=fontprop)\n",
    "# plt.legend(prop=fontprop)\n",
    "# plt.show()\n",
    "\n",
    "# 한글 설정\n",
    "# plt.rcParams['font.family'] ='Malgun Gothic'  # 맑은고딕\n",
    "# plt.rcParams['axes.unicode_minus'] =False   # 마이너스 깨짐 방지\n",
    "\n",
    "# 맥OS에서 안정적으로 작동하는 한글 폰트 설정\n",
    "plt.rcParams['font.family'] = 'AppleGothic'\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "plt.scatter(months, sales, color='blue', label='실제 매출')\n",
    "plt.plot(months, predicted_sales, color='red', label='선형 회귀 예측')\n",
    "plt.xlabel('월')\n",
    "plt.ylabel('매출 (백만 원)')\n",
    "plt.title('선형 회귀 - 월별 매출 예측')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 평균제곱오차를 정의하면 아래와 같다.\n",
    "\n",
    "# 손실함수로 평균제곱오차 정의\n",
    "# y_pred: 예측값 (모델의 출력)\n",
    "# y_true: 실제값 (정답)\n",
    "def mean_squared_error(y_pred, y_true):  # 손실함수가 예측값과 실제값을 입력받는다.\n",
    "    return torch.mean((y_pred - y_true) ** 2)  # 두 값의 차이의 제곱에 평균을 계산하여 손실값을 반환한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## 간단한 선형회귀 적용 실습\n",
    "\n",
    "### `광고비에 따른 자동차 판매량 분석`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 필요한 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 광고비와 자동차 판매량 데이터\n",
    "# 광고비 (단위: 천 원)\n",
    "X = np.array([100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], dtype=np.float32)\n",
    "\n",
    "# 자동차 판매량 (단위: 대)\n",
    "Y = np.array([200, 250, 280, 310, 340, 370, 400, 430, 460, 500], dtype=np.float32)\n",
    "\n",
    "# 데이터를 PyTorch 텐서로 변환, (정규화 0~1)\n",
    "X = torch.tensor(X).view(-1, 1)/1000  # 1000으로 나눠서 0~1 범위로 정규화\n",
    "Y = torch.tensor(Y).view(-1, 1)/500  # 500으로 나눠서 0~1 범위로 정규화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 선형 회귀 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 선형 회귀 모델 정의\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 부모 클래스인 nn.Module의 초기화 메서드를 호출합니다.\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "        # 입력 차원 1, 출력 차원 1인 선형 레이어를 정의합니다.\n",
    "        self.linear = nn.Linear(1, 1)    # 입력 1, 출력 1\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 순전파 함수: 입력 x를 선형 레이어를 통과시켜 출력값을 반환합니다.\n",
    "        return self.linear(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LinearRegressionModel(nn.Module): nn.Module을 상속하여 선형 회귀 모델을 정의하는 클래스입니다. \n",
    "- nn.Module은 PyTorch에서 신경망 모델을 만들 때 상속하는 기본 클래스입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델 초기화\n",
    "model = LinearRegressionModel()\n",
    "\n",
    "# 손실 함수와 최적화 방법 정의\n",
    "criterion = nn.MSELoss()  # 평균 제곱 오차\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "# 경사 하강법 (학습률 0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 학습\n",
    "epochs = 1000  # 반복 횟수\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # 순전파: 예측값 계산\n",
    "    Y_pred = model(X)\n",
    "    # 모델을 사용하여 입력 X에 대한 예측값 Y_pred를 계산합니다.\n",
    "\n",
    "    # 손실 계산\n",
    "    loss = criterion(Y_pred, Y)\n",
    "    # 예측값 Y_pred와 실제값 Y 사이의 손실을 계산합니다.\n",
    "\n",
    "    # 기울기 초기화\n",
    "    optimizer.zero_grad()   # 이전 단계에서 계산된 기울기를 초기화합니다.\n",
    "\n",
    "    # 역전파: 기울기 계산\n",
    "    loss.backward()      # 손실에 대한 기울기를 계산합니다. (오차 역전파)\n",
    "\n",
    "    # 가중치 업데이트\n",
    "    optimizer.step()  # 계산된 기울기를 바탕으로 모델의 가중치를 업데이트합니다.\n",
    "\n",
    "    # 100번마다 손실 출력\n",
    "    if (epoch+1) % 100 == 0:\n",
    "        # 100번째 에폭마다 현재 에폭과 손실 값을 출력합니다.\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loss가 점점 줄어들고 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 학습 결과 확인   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 모델을 사용하여 입력 X에 대한 예측값을 계산한 후,\n",
    "# 계산 그래프에서 분리하고 NumPy 배열로 변환합니다.\n",
    "# detach()는 텐서를 계산 그래프에서 분리하여,\n",
    "# 더 이상 이 텐서에 대해 기울기 계산을 수행하지 않게 만듭니다.\n",
    "predicted = model(X).detach().numpy()\n",
    "\n",
    "# 학습 데이터와 예측 결과 시각화\n",
    "plt.scatter(X.numpy(), Y.numpy(), color='blue', label='Actual data')\n",
    "# 실제 데이터\n",
    "plt.plot(X.numpy(), predicted, color='red', label='pred line')  # 예측된 직선\n",
    "plt.xlabel('Advertising Cost (in thousand units)')\n",
    "plt.ylabel('Car Sales (units)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 새로운 광고비 1200을 1000으로 나누어 텐서로 변환\n",
    "new_ad_cost = torch.tensor([[1200.0]])/1000\n",
    "# 모델을 사용하여 새로운 광고비에 대한 예측 판매량을 계산\n",
    "predicted_sales = model(new_ad_cost).item()*500\n",
    "# 예측된 자동차 판매량을 출력\n",
    "print(f\"예측된 자동차 판매량 (광고비 1200): {predicted_sales:.2f} 대\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 로지스틱 회귀(Logistic Regression)는 이진 분류 문제를 해결하는 대표적인 지도학습 알고리즘입니다.\n",
    "- 로지스틱 회귀의 기본 원리\n",
    "  - 시그모이드 함수를 통해 0~1 사이의 확률 출력\n",
    "  - 결정 경계를 기준으로 클래스 분류\n",
    "  - 선형 분류기의 한 종류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 로지스틱 회귀의 특징"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이진 분류에 최적화\n",
    "- 확률 기반 분류\n",
    "- 선형 결정 경계 생성\n",
    "- 해석이 용이한 모델"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 PyTorch 로지스틱 회귀 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sklearn의 make_classification 함수를 사용하여 가상의 이진 분류 데이터셋을 만들고, \n",
    "- PyTorch로 간단한 로지스틱 회귀 클래스를 정의한 후, 학습 및 평가를 수행합니다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim   # PyTorch의 최적화 함수들을 불러옵니다.\n",
    "from sklearn.datasets import make_classification\n",
    "# 사이킷런에서 분류용 데이터를 생성하는 함수 불러오기\n",
    "from sklearn.model_selection import train_test_split\n",
    "# 데이터셋을 학습용과 테스트용으로 나누는 함수 불러오기\n",
    "\n",
    "# 데이터 생성\n",
    "\n",
    "# make_classification: 분류용 데이터를 생성\n",
    "# n_samples=1000: 데이터셋에 1000개의 샘플을 생성\n",
    "# n_features=20: 각 샘플은 20개의 특성(features)을 가짐\n",
    "# n_classes=2: 두 개의 클래스(0과 1)로 분류되는 문제를 설정\n",
    "# random_state=42: 랜덤 시드를 42로 설정하여 같은 결과 보장\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
    "\n",
    "# 훈련 데이터와 테스트 데이터를 분리\n",
    "#X_train: 훈련 데이터의 특성(입력 변수),\n",
    "# y_train: 훈련 데이터의 목표 변수(출력 값)\n",
    "# train_test_split 함수는 데이터셋 X와 y를 훈련 세트와 테스트 세트로 나누는 함수\n",
    "# test_size=0.2: 데이터의 20%는 테스트 세트, 80%는 훈련 세트\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 모델 학습을 위해서는 데이터를 텐서 형태로 바꿔줘야 함\n",
    "# X_train을 torch.FloatTensor로 변환하여 X_train_tensor에 저장\n",
    "X_train_tensor = torch.FloatTensor(X_train)\n",
    "y_train_tensor = torch.FloatTensor(y_train).view(-1, 1)\n",
    "# y_train을 view(-1, 1)통해 2D Tensor로 변환\n",
    "X_test_tensor = torch.FloatTensor(X_test)\n",
    "y_test_tensor = torch.FloatTensor(y_test).view(-1, 1)\n",
    "\n",
    "# 로지스틱 회귀 모델 정의\n",
    "# LogisticRegressionModel 클래스는 nn.Module을 상속받아 정의된 PyTorch 모델\n",
    "# __init__ 메서드는 클래스의 생성자, 모델을 초기화할 때 호출,\n",
    "# 모델에 필요한 레이어들을 정의\n",
    "# input_dim은 입력 데이터의 차원\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "\n",
    "        # super()는 부모 클래스인 nn.Module의 생성자를 호출\n",
    "        # LogisticRegressionModel 클래스가 nn.Module의 모든 기능을 상속받도록 함\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "\n",
    "        # self.linear는 nn.Linear(입력차원, 출력차원)로 정의된 선형 변환 레이어\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "\n",
    "    # forward 메서드는 모델의 순전파(Forward Pass)를 정의\n",
    "    # 입력 x를 받아 모델을 통해 계산된 출력을 반환하는 역할\n",
    "    # sgmoid출력값을 0과 1 사이의 값으로 변환\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# 로지스틱 회귀 모델 생성\n",
    "# 이진크로스엔트로피\n",
    "# input_dim=20은 모델이 입력으로 받을 데이터의 차원이 20임\n",
    "# criterion는 손실 함수(loss function)를 지정\n",
    "# nn.BCELoss()는 Binary Cross Entropy Loss, 이진 분류 문제\n",
    "model = LogisticRegressionModel(input_dim=20)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# 모델 학습\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 순전파\n",
    "    outputs = model(X_train_tensor)\n",
    "    loss = criterion(outputs, y_train_tensor)\n",
    "\n",
    "    # 역전파 및 최적화\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 모델 평가\n",
    "model.eval()  # 평가 모드로 전환\n",
    "with torch.no_grad():\n",
    "    # 기울기 계산을 비활성화, 평가 중에는 모델의 가중치를 업데이트할 필요가 없음\n",
    "    predicted = model(X_test_tensor)\n",
    "    # 테스트 데이터를 모델에 입력하여 예측값 반환\n",
    "    predicted_class = (predicted > 0.5).float()\n",
    "    # 예측된 확률 값이 0.5보다 크면 1, 아니면 0\n",
    "\n",
    "    # 예측된 클래스(predicted_class)와 실제 클래스(y_test_tensor) 일치 여부 확인\n",
    "    # 동일한 경우 True(1), 다른 경우 False(0)로 반환\n",
    "    # .sum()은 True인 값을 모두 더하여 정확히 예측한 샘플의 수를 구함\n",
    "    # y_test_tensor.size(0)는 테스트 데이터의 총 샘플 수\n",
    "    # 두 값을 나누면 정확도를 계산\n",
    "    # .item()은 결과를 Python 숫자 값으로 변환\n",
    "    # 계산된 정확도를 소수점 4자리까지 출력\n",
    "    accuracy = (predicted_class.eq(y_test_tensor).sum() / y_test_tensor.size(0)).item()\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### 참과 거짓 분류 예제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 데이터 준비\n",
    "torch.manual_seed(0)\n",
    "# 랜덤 시드를 0으로 설정하여 재현 가능한 결과를 얻기 위해 설정\n",
    "data = np.array([[2, 3, 1], [1, 1, 0], [3, 2, 1],\n",
    "                [2, 1, 0], [3, 4, 1], [4, 2, 0]])\n",
    "# 데이터에서 마지막 열을 제외한 나머지 부분을 X로 변환 (입력 데이터)\n",
    "# 데이터에서 마지막 열만 y로 변환 (타겟 레이블)\n",
    "X = torch.tensor(data[:, :-1], dtype=torch.float32)\n",
    "y = torch.tensor(data[:, -1], dtype=torch.float32)\n",
    "\n",
    "# 로지스틱 회귀 모델 정의\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.fc = nn.Linear(2, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.fc(x))\n",
    "\n",
    "# 모델 초기화\n",
    "model = LogisticRegressionModel()\n",
    "\n",
    "# 손실 함수 및 옵티마이저\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 학습\n",
    "epochs = 1000\n",
    "for epoch in range(epochs):\n",
    "    outputs = model(X)\n",
    "\n",
    "    # squeeze() 메서드를 호출하여 차원을 축소\n",
    "    loss = criterion(outputs.squeeze(), y)\n",
    "    # 예측값(outputs)과 실제값(y)을 비교하여 손실(loss)을 계산\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0:  # 에포크 번호가 100으로 나누어떨어질 때마다 실행\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# 평가\n",
    "with torch.no_grad():\n",
    "    predicted = model(X).round()\n",
    "    # 모델을 사용해 입력 X에 대한 예측을 수행하고,\n",
    "    # 예측값을 반올림 (0 또는 1로 만듦)\n",
    "    # 예측값과 실제값 y가 일치하는 비율을 계산하여 정확도 측정\n",
    "    accuracy = (predicted.squeeze() == y).sum().item() / y.size(0) * 100\n",
    "    print(f'Accuracy: {accuracy:.2f}%')\n",
    "\n",
    "# 시각화\n",
    "# 입력 데이터 X의 첫 번째 특징의 최솟값, 최대값 구하고\n",
    "# 시각화할 X축 범위 설정 -1, 1로 그래프 여백 추가\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "# 입력 데이터 X의 첫 번째 특징의 최솟값, 최대값\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "# x_min에서 x_max까지 100개의 균등한 값으로 나눔,\n",
    "# meshgrid는 2D배열 되고 시각화 가능\n",
    "xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))\n",
    "grid = torch.tensor(np.c_[xx.ravel(), yy.ravel()], dtype=torch.float32)\n",
    "# 텐서 변환\n",
    "\n",
    "with torch.no_grad():\n",
    "    Z = model(grid).round().numpy().reshape(xx.shape)\n",
    "\n",
    "plt.contourf(xx, yy, Z, alpha=0.8)\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', marker='o', s=100, linewidth=1)\n",
    "plt.title('Logistic Regression Classification')\n",
    "plt.xlabel('Feature 1')\n",
    "plt.ylabel('Feature 2')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
