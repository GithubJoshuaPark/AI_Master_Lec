{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 영상필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv2.filter2D(src, ddepth, kernel[, dst[, anchor[, delta[, borderType]]]]) -> dst\n",
    "# src: 입력영상\n",
    "# ddepth: 출력영상의 타입 (cv2.CV_8U, cv2.CV_32F, cv2.CV_64F), \n",
    "#     -1 => 입력영상과 같은 타입\n",
    "# kernel: filter 행렬, 실수형\n",
    "# anchor: (-1, -1)  필터의 중앙점\n",
    "# delta:   더할 값\n",
    "# borderType: 가장자리 픽셀확장 방식\n",
    "# dst: 출력영상\n",
    "\n",
    "# blur(src, ksize[, dst[, anchor[, borderType]]]) -> dst\n",
    "# src: 입력영상\n",
    "# ksize: mean filter kernel size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 영역처리, 영상 필터링, Convolution\n",
    "\n",
    "src = cv2.imread(\"./fig/blue_eyes.png\", cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "kernel_3 = np.ones((3, 3), dtype = np.float64)/9.\n",
    "dst_kernel = cv2.filter2D(src, -1, kernel_3)\n",
    "\n",
    "dst_blur = cv2.blur(src, (3, 3))\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst_kernel', dst_kernel)\n",
    "cv2.imshow(\"dst_blur\", dst_blur)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/blue_eyes.png\", cv2.IMREAD_REDUCED_COLOR_2)\n",
    "cv2.imshow(\"src\", src)\n",
    "\n",
    "for ksize in (3, 5, 7, 9, 12, 15, 23):\n",
    "    dst = cv2.blur(src, (ksize, ksize))\n",
    "    text = '{} x {}'.format(ksize, ksize)\n",
    "    cv2.putText(dst, text, (20, 30), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('mean filter', dst)\n",
    "    cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 가우시안 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GaussianBlur(src, (ksize), sigmaX[, dst[, sigmaY[, borderType]]]) -> dst\n",
    "# src: 입력영상\n",
    "# ksize: mean filter kernel size, (0, 0) 자동으로 결정\n",
    "# sigmaX:  gaussian x 방향의 sigma\n",
    "# sigmaY:  gaussian y 방향의 sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 가우시안 필터\n",
    "\n",
    "src = cv2.imread(\"./fig/blue_eyes.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "dst_Gaussian1 = cv2.GaussianBlur(src, (0, 0), 1)\n",
    "dst_mean = cv2.blur(src, (5,5))\n",
    "# dst_Gaussian2 = cv2.GaussianBlur(src, (0, 0), 2)\n",
    "# dst_Gaussian3 = cv2.GaussianBlur(src, (0, 0), 3)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow(\"Gaussian1\", dst_Gaussian1)\n",
    "cv2.imshow(\"dst_mean\", dst_mean)\n",
    "# cv2.imshow(\"Gaussian2\", dst_Gaussian2)\n",
    "# cv2.imshow(\"Gaussianㅗ3\", dst_Gaussian3)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 사프닝 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sharpening filter\n",
    "\n",
    "src = cv2.imread(\"./fig/blue_eyes.png\", cv2.IMREAD_REDUCED_COLOR_2)\n",
    "\n",
    "blr = cv2.GaussianBlur(src, (0, 0), 1)\n",
    "blr2 = cv2.GaussianBlur(src, (0, 0), 2)\n",
    "blr3 = cv2.GaussianBlur(src, (0, 0), 3)\n",
    "\n",
    "dst = cv2.addWeighted(src, 2, blr, -1, 0.0)\n",
    "dst2 = cv2.addWeighted(src, 2, blr2, -1, 0.0)\n",
    "dst3 = cv2.addWeighted(src, 2, blr3, -1, 0.0)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow(\"blr\", blr)\n",
    "cv2.imshow(\"sharpening1\", dst)\n",
    "cv2.imshow(\"sharpening2\", dst2)\n",
    "cv2.imshow(\"sharpening3\", dst3)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# [[ 0. -1.  0.]\n",
    "#  [-1.  5. -1.]\n",
    "#  [ 0. -1.  0.]]\n",
    "\n",
    "# [[-0.2 -0.8 -0.2]\n",
    "#  [-0.8  5.  -0.8]\n",
    "#  [-0.2 -0.8 -0.2]]\n",
    "\n",
    "# src = cv2.imread('blue_eyes.png', cv2.IMREAD_REDUCED_COLOR_2)\n",
    "# kernel = np.ones((3, 3), dtype = np.float64)*-1\n",
    "# kernel[1,1] = 9\n",
    "# #print(kernel)\n",
    "# dst = cv2.filter2D(src, -1, kernel)\n",
    "# cv2_imshow(src)\n",
    "# cv2_imshow(dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAABSFJREFUeJzt1zFxA0EQRcE71aE4FCLhEgKhFAKXSRiFYXidvdRKpN2gO57gZ69mH2OMDQC2bbvMHgDAOkQBgIgCABEFACIKAEQUAIgoABBRACDHs4cfl/srdwDwYl+/j39vfAoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAyDF7AOv5/PmePYE3up3X2RNYiE8BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCADlmD2A9t/M6ewIwiU8BgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAEBEAYCIAgARBQAiCgBEFACIKAAQUQAgogBARAGAiAIAEQUAIgoARBQAiCgAEFEAIKIAQEQBgIgCABEFALKPMcbsEQCswacAQEQBgIgCABEFACIKAEQUAIgoABBRACCiAED+APoZEZilqv7lAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## sharpen filter\n",
    "src = cv2.imread(\"./fig/blue_eyes.png\")\n",
    "\n",
    "kernel_3 = np.ones((3, 3), dtype = np.float64)*-.5\n",
    "kernel_3[1, 1] = 5\n",
    "\n",
    "dst_kernel = cv2.filter2D(src, -1, kernel_3)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('dst_kernel', dst_kernel)\n",
    "\n",
    "plt.imshow(kernel_3)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "# cv2.imshow(\"dst_blur\", dst_blur)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 중앙값 필터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## median filter\n",
    "src = cv2.imread(\"./fig/blue_eyes.png\", cv2.IMREAD_GRAYSCALE)\n",
    "salt_noise = np.random.choice((0, 255), src.shape, p = (0.99, 0.01)).astype(np.uint8)\n",
    "pepper_noise = np.random.choice((0, 255), src.shape, p = (0.99, 0.01)).astype(np.uint8)\n",
    "dst = cv2.add(src, salt_noise)\n",
    "dst = cv2.subtract(dst, pepper_noise)\n",
    "\n",
    "dst_median = cv2.medianBlur(dst, 3)\n",
    "# dst_Gaussian = cv2.GaussianBlur(dst, (0, 0), 1)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "# cv2.imshow(\"salt_noise\", salt_noise)\n",
    "# cv2.imshow(\"pepper_noise\", pepper_noise)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "cv2.imshow(\"dst_median\", dst_median)\n",
    "# cv2.imshow(\"dst_Gaussian\", dst_Gaussian)\n",
    "\n",
    "\n",
    "while True:\n",
    "    if cv2.waitKey() == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 양방향 필터 (Bilateral filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## \n",
    "# bilateralFilter(src, d, sigmaColor, sigmaSpace[, dst[, borderType]]) -> dst\n",
    "# src: 입력영상\n",
    "# d: -1로 설정\n",
    "# sigmaColor: 색공간의 표준편차\n",
    "# sigmaSpace: 좌표공간의표준편차\n",
    "# dst:\n",
    "# borderType: 가장자리 픽셀확장 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = cv2.imread(\"./fig/blue_eyes.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "dst_Gaussian = cv2.GaussianBlur(src, (0, 0), 1. )\n",
    "dst_Bilateral_5 = cv2.bilateralFilter(src, -1, 5, 10)\n",
    "dst_Bilateral_20 = cv2.bilateralFilter(src, -1, 20, 10)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"Gaussian\", dst_Gaussian)\n",
    "cv2.imshow(\"Bilateral_5\", dst_Bilateral_5)\n",
    "cv2.imshow(\"Bilateral_20\", dst_Bilateral_20)\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 카툰 필터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## bitwise operator\n",
    "src1 = np.zeros((256, 256), np.uint8)\n",
    "cv2.rectangle(src1, (10, 10), (127, 245), 255, -1)\n",
    "src2 = np.zeros((256, 256), np.uint8)\n",
    "cv2.circle(src2, (127, 127), 100, 128, -1)\n",
    "\n",
    "dst1 = cv2.bitwise_and(src1, src2)\n",
    "dst2 = cv2.bitwise_or(src1, src2)\n",
    "dst3 = cv2.bitwise_xor(src1, src2)\n",
    "dst4 = cv2.bitwise_not(src2)\n",
    "\n",
    "cv2.imshow(\"src1\", src1)\n",
    "cv2.imshow('src2', src2)\n",
    "cv2.imshow(\"AND\", dst1)\n",
    "cv2.imshow(\"OR\", dst2)\n",
    "cv2.imshow(\"XOR\", dst3)\n",
    "cv2.imshow(\"NOT\", dst4)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276.297 ms\n"
     ]
    }
   ],
   "source": [
    "## Cartoon 필터\n",
    "\n",
    "time = cv2.TickMeter()\n",
    "\n",
    "src = cv2.imread(\"./fig/son.jpg\")\n",
    "\n",
    "time.start()\n",
    "\n",
    "### 연산 구간\n",
    "for i in range(100):\n",
    "    blr = cv2.GaussianBlur(src, (0, 0), 2)\n",
    "    edge = 255 - cv2.Canny(src, 100, 200)\n",
    "    edge = cv2.cvtColor(edge, cv2.COLOR_GRAY2BGR)\n",
    "    dst = cv2.bitwise_and(blr, edge)\n",
    "###\n",
    "\n",
    "time.stop()\n",
    "\n",
    "cv2.imshow(\"son\", src)\n",
    "cv2.imshow(\"blr\", blr)\n",
    "cv2.imshow(\"edge\", edge)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "print(time.getTimeMilli(), \"ms\")\n",
    "time.reset()\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 영상 이동"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
    "# src: 입력영상\n",
    "# M: affine transform matrix (size: 2 x 3)\n",
    "# dsize: 출력영상 크기, (0, 0) = 입력영상크기로 출력\n",
    "# borderValue: 값이 없는 영역을 채우는 값, default  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "affine matrix: \n",
      " [[  1.   0.  50.]\n",
      " [  0.   1. 200.]]\n"
     ]
    }
   ],
   "source": [
    "## 영상 이동 (Translation)\n",
    "\n",
    "src = cv2.imread(\"./fig/dog.bmp\")\n",
    "\n",
    "## affine matrix\n",
    "affine = np.array([[1, 0, 50],\n",
    "                   [0, 1, 200]], np.float32)\n",
    "\n",
    "print(\"affine matrix: \\n\", affine)\n",
    "# print(affine.dtype)\n",
    "\n",
    "dst = cv2.warpAffine(src, affine, (0, 0), \n",
    "                     borderMode = cv2.BORDER_CONSTANT, \n",
    "                     borderValue=(255, 255, 255))\n",
    "\n",
    "# dst = cv2.warpAffine(src, affine, (0, 0))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. 영상 회전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warpAffine(src, M, dsize[, dst[, flags[, borderMode[, borderValue]]]]) -> dst\n",
    "# src: 입력영상\n",
    "# M: affine transform matrix (size: 2 x 3)\n",
    "# dsize: 출력영상 크기, (0, 0) = 입력영상크기로 출력\n",
    "# borderValue: 값이 없는 영역을 채우는 값, default  = 0\n",
    "\n",
    "# getRotationMatrix2D(center, angle, scale) -> retval\n",
    "# center: 영상의 center\n",
    "# angle: 회전각도\n",
    "# scale: 확대율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 회전 변환 (Rotation)\n",
    "\n",
    "src = cv2.imread(\"./fig/dog.bmp\")\n",
    "\n",
    "cp = (src.shape[1]/2, src.shape[0]/2)\n",
    "affine = cv2.getRotationMatrix2D(cp,  30, 1.)\n",
    "dst = cv2.warpAffine(src, affine, (0, 0))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src shape :  (461, 600, 3)\n"
     ]
    }
   ],
   "source": [
    "## 영상 확대 (Scaling)\n",
    "src = cv2.imread(\"./fig/rose.jpg\")\n",
    "print(\"src shape : \", src.shape)\n",
    "\n",
    "dst1 = cv2.resize(src, (1900, 1300), interpolation=cv2.INTER_NEAREST)\n",
    "dst2 = cv2.resize(src, (1900, 1300), interpolation=cv2.INTER_LINEAR)\n",
    "dst3 = cv2.resize(src, (1900, 1300), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow('INTER_NEAREST', dst1[800:1600, 800:1200])\n",
    "cv2.imshow('INTER_LINEAR', dst2[800:1600, 800:1200])\n",
    "cv2.imshow('INTER_CUBIC', dst3[800:1600, 800:1200])\n",
    "\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. 영상 전단"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Shearing\n",
    "src = cv2.imread(\"./fig/dog.bmp\")\n",
    "\n",
    "affine  = np.array([[1, 0.2, 0],\n",
    "                    [0.2, 1, 0 ]], np.float32)\n",
    "\n",
    "dst = cv2.warpAffine(src, affine, (0, 0))\n",
    "\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. 비선형 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getPerspectiveTransform(src, dst[, solveMethod]) -> retval\n",
    "# src: 입력영상의 4개 좌표점, numpy array shape(4,2)\n",
    "# dst: 출력영상의 4개 좌표점, numpy array shape(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "width =  960 height =  540\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "## Non linear warping\n",
    "\n",
    "src = cv2.imread(\"./fig/checkerboard.png\")\n",
    "\n",
    "h, w = src.shape[:2]\n",
    "\n",
    "srcPoint = np.array([[218, 48], [691, 47], [830, 518], [67, 527]], np.float32)\n",
    "dstPoint = np.array([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]], np.float32)\n",
    "\n",
    "pers = cv2.getPerspectiveTransform(srcPoint, dstPoint)\n",
    "# array([[ 2.13264257e+00,  6.72294421e-01, -4.97186212e+02],\n",
    "#        [ 4.08735101e-03,  1.93331703e+00, -9.36902599e+01],\n",
    "#        [-1.86504523e-05,  1.36282733e-03,  1.00000000e+00]])\n",
    "\n",
    "dst = cv2.warpPerspective(src, pers, (w, h))\n",
    "# a, b, c, d = cv2.selectROI(src)\n",
    "# print(a, b, c, d)\n",
    "\n",
    "print(\"width = \", w, \"height = \", h)\n",
    "cv2.imshow(\"src\", src)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
