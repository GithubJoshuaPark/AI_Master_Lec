{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "import numpy as np\n",
    "import cv2 # opencv-python which is an Open Source Computer Vision Library\n",
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt # matplotlib.pyplot which provides a MATLAB-like plotting framework\n",
    "\n",
    "def close_window():\n",
    "    cv2.destroyAllWindows()  # Close the window\n",
    "    cv2.waitKey(1)\n",
    "    cv2.waitKey(1)\n",
    "    \n",
    "def ifNotExistExit(filename):\n",
    "    if not filename:\n",
    "        print('filename is None')\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines.shape: (109, 1, 4)\n"
     ]
    }
   ],
   "source": [
    "## Hough line detection\n",
    "src = cv2.imread('./fig/checkerboard.png', cv2.IMREAD_GRAYSCALE)\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "edges = cv2.Canny(src, 50, 150)\n",
    "lines = cv2.HoughLinesP(edges, 1, np.pi / 360, 60, minLineLength=10, maxLineGap=20) # cv2.CV_32F\n",
    "print('lines.shape:', lines.shape) # (n, 1, 2)\n",
    "\n",
    "dst = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for i in range(lines.shape[0]):\n",
    "    pt1 = (lines[i][0][0], lines[i][0][1])\n",
    "    pt2 = (lines[i][0][2], lines[i][0][3])\n",
    "    cv2.line(dst, pt1, pt2, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "    cv2.putText(dst, str(i), pt1, cv2.FONT_HERSHEY_SIMPLEX, 0.3, (255, 0, 0), 1, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('edges', edges)\n",
    "cv2.imshow(\"dst\", dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "close_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnt: 124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 19:15:48.351 python[15042:629397] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-25 19:15:48.351 python[15042:629397] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "## 연결 객체 검출: 레이블링\n",
    "src = cv2.imread('./fig/keyboard.jpg')\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# mask 하는 이유는 흰색을 255(컴퓨터는 255를 물채로 인식)로 하고 \n",
    "# 검은색을 0으로 하기 위해서임\n",
    "_, mask = cv2.threshold(src_gray, 120, 255, cv2.THRESH_BINARY_INV) \n",
    "cnt, labels, stats, centroids = cv2.connectedComponentsWithStats(mask)\n",
    "\n",
    "# cnt\n",
    "print('cnt:', cnt)\n",
    "\n",
    "for i in range(1, cnt):\n",
    "    (x, y, w, h, area) = stats[i]\n",
    "    if area <= 200:\n",
    "        continue\n",
    "    cv2.rectangle(src, (x, y, w, h), (0, 0, 255), 2)\n",
    "    cv2.putText(src, str(i), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('mask', mask)\n",
    "cv2.imshow('src_gray', src_gray)\n",
    "\n",
    "cv2.waitKey()\n",
    "close_window()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 외곽선 검출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 외곽선 검출 from ./fig/shapes.png\n",
    "src = cv2.imread('./fig/shape.png')\n",
    "\n",
    "if src is None:\n",
    "    print('Image load failed!')\n",
    "    sys.exit()\n",
    "\n",
    "\n",
    "# computer regcognize white color as 255 and black color as 0\n",
    "# so, object should be white and background should be black\n",
    "# (This is opposite to human's eye)\n",
    "# So, we need to convert the image to binary image\n",
    "src_gray = cv2.cvtColor(src, cv2.COLOR_BGR2GRAY)\n",
    "_, src_bin = cv2.threshold(src_gray, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "cv2.imshow('src', src)\n",
    "cv2.imshow('src_gray', src_gray)\n",
    "\n",
    "\n",
    "# cv2.RETR_EXTERNAL: 외곽선 중 가장 바깥쪽의 외곽선만 찾음\n",
    "# cv2.CHAIN_APPROX_NONE: 외곽선을 구성하는 모든 점을 반환\n",
    "# contours: 외곽선 좌표\n",
    "# _ : 계층 정보\n",
    "contours, _ = cv2.findContours(src_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "dst = cv2.cvtColor(src_bin, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for i in range(len(contours)):    \n",
    "    cv2.drawContours(dst, contours, i, (255, 0, 0), 2) # blue\n",
    "    cv2.putText(dst, str(i), tuple(contours[i][0][0]), cv2.FONT_HERSHEY_PLAIN, 1, (0,0,255), 1, cv2.LINE_AA) # red\n",
    "    \n",
    "cv2.imshow('src_bin', src_bin)\n",
    "cv2.imshow('dst', dst)\n",
    "\n",
    "cv2.waitKey()\n",
    "close_window()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 동영상 처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-25 21:31:02.888 python[20754:818538] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-25 21:31:02.888 python[20754:818538] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "cap = cv2.VideoCapture('./fig/video/PETS2000.avi')\n",
    "if not cap.isOpened():\n",
    "    print('Video open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "# get the first frame as the background\n",
    "ret, back = cap.read()\n",
    "if not ret:\n",
    "    print('Background image registration failed!')\n",
    "    sys.exit()\n",
    "\n",
    "back = cv2.cvtColor(back, cv2.COLOR_BGR2GRAY) # convert to gray scale\n",
    "    \n",
    "cap.isOpened()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read() # ret: True or False, frame: image data (from the first frame to the last frame)\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    diff = cv2.absdiff(gray, back) # difference between the current frame and the background\n",
    "    _, diff = cv2.threshold(diff, 30, 255, cv2.THRESH_BINARY) # thresholding\n",
    "    diff_red = cv2.cvtColor(diff, cv2.COLOR_GRAY2BGR) # convert to color image\n",
    "    diff_red[:,:,2] = 0\n",
    "    \n",
    "    cnts, labels, stats, centroids = cv2.connectedComponentsWithStats(diff)\n",
    "    for i in range(1, cnts):\n",
    "        (x, y, w, h, area) = stats[i]\n",
    "        if area < 100:\n",
    "            continue\n",
    "        cv2.rectangle(frame, (x, y, w, h), (0, 0, 255), 2)\n",
    "        cv2.putText(frame, str(i), (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 1)\n",
    "    \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('diff', diff_red) \n",
    "    \n",
    "    if cv2.waitKey(10) == 27: # ESC key\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey() # wait until any key,'q' is pressed\n",
    "close_window()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Webcam (macbook pro Intel cpu)\n",
    "# WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print('Camera open failed!')\n",
    "    sys.exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    edge = cv2.Canny(frame, 50, 150)\n",
    "    frame_gaussian = cv2.GaussianBlur(frame, (0, 0), 2)\n",
    "    frame_gray = cv2.cvtColor(frame_gaussian, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray_inversed = cv2.bitwise_not(frame_gray)\n",
    "    edge_gaussian = cv2.Canny(frame_gaussian, 50, 150)\n",
    "        \n",
    "    cv2.imshow('frame', frame)\n",
    "    cv2.imshow('edge', edge)\n",
    "    cv2.imshow('frame_gaussian', frame_gaussian)\n",
    "    cv2.imshow('frame_gray', frame_gray)\n",
    "    cv2.imshow('frame_gray_inversed', frame_gray_inversed)\n",
    "    cv2.imshow('edge_gaussian', edge_gaussian)\n",
    "    \n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.waitKey()\n",
    "close_window()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 기하학적 모멘트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 기하학적 모멘트 (Hu moment)\n",
    "obj = cv2.imread('./fig/spades.png', cv2.IMREAD_GRAYSCALE)\n",
    "src = cv2.imread('./fig/symbols.png', cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "_, obj_bin = cv2.threshold(obj, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "obj_contours, _ = cv2.findContours(obj_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "obj_pts = obj_contours[0]\n",
    "\n",
    "_, src_bin = cv2.threshold(src, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "src_contours, _ = cv2.findContours(src_bin, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "dst = cv2.cvtColor(src, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "for pts in src_contours:\n",
    "    if cv2.contourArea(pts) < 1000:\n",
    "        continue\n",
    "    rc = cv2.boundingRect(pts)\n",
    "    cv2.rectangle(dst, rc, (255, 0, 0), 1)\n",
    "    dist = cv2.matchShapes(obj_pts, pts, cv2.CONTOURS_MATCH_I3, 0)\n",
    "    cv2.putText(dst, str(round(dist, 3)), (rc[0], rc[1] - 3), cv2.FONT_HERSHEY_COMPLEX, 0.8,\n",
    "                (255, 0, 0), 1, cv2.LINE_AA)\n",
    "    \n",
    "    if dist < 0.1:\n",
    "        cv2.rectangle(dst, rc, (0, 0, 255), 2)\n",
    "        cv2.putText(dst, str(round(dist, 3)), (rc[0], rc[1] - 3), cv2.FONT_HERSHEY_COMPLEX, 0.8,\n",
    "                (0, 0, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "cv2.imshow('dst', dst)\n",
    "cv2.imshow('obj_bin', obj_bin)\n",
    "cv2.imshow('src_bin', src_bin)\n",
    "\n",
    "cv2.waitKey()\n",
    "close_window()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
